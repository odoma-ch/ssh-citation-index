{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642ac9f2",
   "metadata": {},
   "source": [
    "# Citation Search Result Coverage and HF Dataset Prep\n",
    "\n",
    "This notebook loads the aggregated search results, reports coverage statistics for each external source, and prepares a Hugging Face DatasetDict with one split per reference source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e7c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 759 reference records from results_20251020_124218_limitNone_openalex_wikidata_matilda.json\n",
      "Reference sources: ['cex', 'excite', 'linkedbook']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "DATA_PATH = Path(\"results_20251020_124218_limitNone_openalex_wikidata_matilda.json\")\n",
    "\n",
    "with DATA_PATH.open() as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(records)} reference records from {DATA_PATH}\")\n",
    "sources = sorted({record.get(\"source\", \"unknown\") for record in records})\n",
    "print(f\"Reference sources: {sources}\")\n",
    "providers = [\"openalex\", \"matilda\", \"wikidata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f436d0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "success_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "success_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "top_result_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "top_result_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_match_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_match_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_match_count",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_match_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_title_similarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_author_similarity",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "824f0ed5-10df-4d23-9cdd-f947c0b90b2f",
       "rows": [
        [
         "openalex",
         "757.0",
         "0.997364953886693",
         "593.0",
         "0.7812911725955204",
         "383.0",
         "0.5046113306982872",
         "385.0",
         "0.5072463768115942",
         "87.41652613827993",
         "61.97639123102867"
        ],
        [
         "matilda",
         "757.0",
         "0.997364953886693",
         "421.0",
         "0.5546772068511199",
         "314.0",
         "0.4137022397891963",
         "280.0",
         "0.3689064558629776",
         "99.3372921615202",
         "67.58194774346794"
        ],
        [
         "wikidata",
         "757.0",
         "0.997364953886693",
         "161.0",
         "0.21212121212121213",
         "124.0",
         "0.16337285902503293",
         "124.0",
         "0.16337285902503293",
         "93.42857142857143",
         "59.15527950310559"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>success_count</th>\n",
       "      <th>success_rate</th>\n",
       "      <th>top_result_count</th>\n",
       "      <th>top_result_rate</th>\n",
       "      <th>is_match_count</th>\n",
       "      <th>is_match_rate</th>\n",
       "      <th>year_match_count</th>\n",
       "      <th>year_match_rate</th>\n",
       "      <th>mean_title_similarity</th>\n",
       "      <th>mean_author_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>openalex</th>\n",
       "      <td>757.0</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0.781291</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>87.416526</td>\n",
       "      <td>61.976391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matilda</th>\n",
       "      <td>757.0</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.554677</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.413702</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.368906</td>\n",
       "      <td>99.337292</td>\n",
       "      <td>67.581948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikidata</th>\n",
       "      <td>757.0</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>93.428571</td>\n",
       "      <td>59.155280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          success_count  success_rate  top_result_count  top_result_rate  \\\n",
       "openalex          757.0      0.997365             593.0         0.781291   \n",
       "matilda           757.0      0.997365             421.0         0.554677   \n",
       "wikidata          757.0      0.997365             161.0         0.212121   \n",
       "\n",
       "          is_match_count  is_match_rate  year_match_count  year_match_rate  \\\n",
       "openalex           383.0       0.504611             385.0         0.507246   \n",
       "matilda            314.0       0.413702             280.0         0.368906   \n",
       "wikidata           124.0       0.163373             124.0         0.163373   \n",
       "\n",
       "          mean_title_similarity  mean_author_similarity  \n",
       "openalex              87.416526               61.976391  \n",
       "matilda               99.337292               67.581948  \n",
       "wikidata              93.428571               59.155280  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize_provider(records: list[dict], provider: str) -> Dict[str, Optional[float]]:\n",
    "    total_records = len(records)\n",
    "    success_count = 0\n",
    "    top_result_count = 0\n",
    "    match_count = 0\n",
    "    year_match_count = 0\n",
    "    title_sims: list[float] = []\n",
    "    author_sims: list[float] = []\n",
    "\n",
    "    for record in records:\n",
    "        metadata = (record.get(\"search_results\") or {}).get(provider, {}).get(\"metadata_search\")\n",
    "        if not metadata:\n",
    "            continue\n",
    "        if metadata.get(\"success\"):\n",
    "            success_count += 1\n",
    "        top_result = metadata.get(\"top_result\")\n",
    "        if not top_result:\n",
    "            continue\n",
    "        top_result_count += 1\n",
    "        if top_result.get(\"is_match\"):\n",
    "            match_count += 1\n",
    "        match_details = top_result.get(\"match_details\") or {}\n",
    "        title_sim = match_details.get(\"title_similarity\")\n",
    "        author_sim = match_details.get(\"author_similarity\")\n",
    "        if title_sim is not None:\n",
    "            title_sims.append(float(title_sim))\n",
    "        if author_sim is not None:\n",
    "            author_sims.append(float(author_sim))\n",
    "        if match_details.get(\"year_match\"):\n",
    "            year_match_count += 1\n",
    "\n",
    "    mean_title_sim = float(pd.Series(title_sims).mean()) if title_sims else None\n",
    "    mean_author_sim = float(pd.Series(author_sims).mean()) if author_sims else None\n",
    "\n",
    "    return {\n",
    "        \"success_count\": success_count,\n",
    "        \"success_rate\": success_count / total_records if total_records else 0.0,\n",
    "        \"top_result_count\": top_result_count,\n",
    "        \"top_result_rate\": top_result_count / total_records if total_records else 0.0,\n",
    "        \"is_match_count\": match_count,\n",
    "        \"is_match_rate\": match_count / total_records if total_records else 0.0,\n",
    "        \"year_match_count\": year_match_count,\n",
    "        \"year_match_rate\": year_match_count / total_records if total_records else 0.0,\n",
    "        \"mean_title_similarity\": mean_title_sim,\n",
    "        \"mean_author_similarity\": mean_author_sim,\n",
    "    }\n",
    "\n",
    "summary = {provider: summarize_provider(records, provider) for provider in providers}\n",
    "stats_df = pd.DataFrame(summary).T\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2a763",
   "metadata": {},
   "source": [
    "## Build Hugging Face dataset\n",
    "\n",
    "We expand every reference across the available providers and materialize a DatasetDict where each split key corresponds to the reference source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def347b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    openalex: Dataset({\n",
       "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
       "        num_rows: 759\n",
       "    })\n",
       "    matilda: Dataset({\n",
       "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
       "        num_rows: 759\n",
       "    })\n",
       "    wikidata: Dataset({\n",
       "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
       "        num_rows: 759\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_openalex_id(raw_id: Optional[str]) -> Optional[str]:\n",
    "    if not raw_id:\n",
    "        return None\n",
    "    cleaned = raw_id.rstrip(\"/\")\n",
    "    return cleaned.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "def build_matched_id(provider: str, ids: Dict[str, Any]) -> Optional[str]:\n",
    "    if provider == \"openalex\":\n",
    "        return extract_openalex_id(ids.get(\"openalex_id\"))\n",
    "    if provider == \"matilda\":\n",
    "        return ids.get(\"matilda_id\")\n",
    "    if provider == \"wikidata\":\n",
    "        return ids.get(\"wikidata_id\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_matched_link(provider: str, matched_id: Optional[str]) -> Optional[str]:\n",
    "    search_links = {\n",
    "        \"openalex\": \"https://openalex.org/\",\n",
    "        \"matilda\": \"https://matilda.science/?l=en\",\n",
    "        \"wikidata\": \"https://www.wikidata.org/wiki/Wikidata:Main_Page\",\n",
    "    }\n",
    "    if matched_id:\n",
    "        if provider == \"openalex\":\n",
    "            return f\"https://openalex.org/works?zoom={matched_id.lower()}\"\n",
    "        if provider == \"matilda\":\n",
    "            return f\"https://matilda.science/work/{matched_id}\"\n",
    "        if provider == \"wikidata\":\n",
    "            return f\"https://www.wikidata.org/wiki/{matched_id}\"\n",
    "    return search_links.get(provider)\n",
    "\n",
    "\n",
    "def resolve_is_match(metadata: Optional[Dict[str, Any]]) -> bool:\n",
    "    if not metadata:\n",
    "        return False\n",
    "    top_result = metadata.get(\"top_result\") or {}\n",
    "    is_match = top_result.get(\"is_match\")\n",
    "    if is_match is not None:\n",
    "        return bool(is_match)\n",
    "    match_details = top_result.get(\"match_details\") or {}\n",
    "    title_similarity = match_details.get(\"title_similarity\")\n",
    "    if title_similarity is None:\n",
    "        return False\n",
    "    return float(title_similarity) >= 90.0\n",
    "\n",
    "\n",
    "def summarize_top_result(top_result: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    fields = [\"title\", \"first_author\", \"year\", \"journal\"]\n",
    "    data = top_result or {}\n",
    "    return {field: data.get(field) for field in fields}\n",
    "\n",
    "\n",
    "def matched_result_to_text(m: Optional[Dict[str, Any]]) -> str:\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    parts = []\n",
    "    for k in (\"title\", \"first_author\", \"year\", \"journal\"):\n",
    "        v = m.get(k)\n",
    "        if v:\n",
    "            parts.append(f\"{k}: {v}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "\n",
    "split_rows: dict[str, list[dict[str, Any]]] = defaultdict(list)\n",
    "\n",
    "for record in records:\n",
    "    base_row = {\n",
    "        \"ref_id\": record.get(\"ref_id\"),\n",
    "        \"original_ref_string\": record.get(\"original_string\"),\n",
    "        # \"reference_source\": record.get(\"source\"),\n",
    "    }\n",
    "    search_results = record.get(\"search_results\") or {}\n",
    "    for provider in providers:\n",
    "        metadata = (search_results.get(provider) or {}).get(\"metadata_search\")\n",
    "        top_result = metadata.get(\"top_result\") if metadata else None\n",
    "        ids = (top_result or {}).get(\"ids\") or {}\n",
    "        matched_id = build_matched_id(provider, ids)\n",
    "        row = {\n",
    "            **base_row,\n",
    "            \"matched_id\": matched_id or \"Not Found\",\n",
    "            \"matched_doi\": ids.get(\"doi\") or \"\",\n",
    "            \"matched_result\": summarize_top_result(top_result),\n",
    "            \"is_match_by_similarity\": resolve_is_match(metadata),\n",
    "            \"matched_link\": build_matched_link(provider, matched_id),\n",
    "        }\n",
    "        split_rows[provider].append(row)\n",
    "\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    split: Dataset.from_list(rows)\n",
    "    for split, rows in split_rows.items()\n",
    "})\n",
    "\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3287b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    openalex: Dataset({\n",
      "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
      "        num_rows: 759\n",
      "    })\n",
      "    matilda: Dataset({\n",
      "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
      "        num_rows: 759\n",
      "    })\n",
      "    wikidata: Dataset({\n",
      "        features: ['ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
      "        num_rows: 759\n",
      "    })\n",
      "})\n",
      "Preview split: openalex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ref_id': ['cex_BIO-GEN-MOL_9_1',\n",
       "  'cex_BIO-GEN-MOL_9_0',\n",
       "  'cex_BIO-GEN-MOL_9_3',\n",
       "  'cex_BIO-GEN-MOL_9_2',\n",
       "  'cex_BIO-GEN-MOL_9_4'],\n",
       " 'original_ref_string': ['L R Leddy, R E Holmes. Chondrosarcoma of bone. Cancer Treat Res. 2014. Vol. 162',\n",
       "  'A Y Giuffrida, J E Burgueno, L G Koniaris, J C Gutierrez, R Duncan, S P Scully. Chondrosarcoma in the United States (1973 to 2003): an analysis of 2890 cases from the SEER database. J Bone Joint Surg Am. 2009. Vol. 91',\n",
       "  'E Lhuissier, C Bazille, J Aury-Landas, N Girard, J Pontin, M Boittin, K Boumediene, C Baugé. Identification of an easy to use 3D culture model to investigate invasion and anticancer drug response in chondrosarcomas. BMC Cancer. 2017. Vol. 17',\n",
       "  'N Girard, C Bazille, E Lhuissier, H Benateau, A Llombart-Bosch, K Boumediene, C Baugé. 3-Deazaneplanocin A (DZNep), an Inhibitor of the Histone Methyltransferase EZH2, Induces Apoptosis and Reduces Cell Migration in Chondrosarcoma Cells. PloS One. 2014. Vol. 9. pp. e98176',\n",
       "  'J Puppe, R Drost, X Liu, S A Joosse, B Evers, P Cornelissen-Steijger, P Nederlof, Q Yu, J Jonkers, M van Lohuizen, A M Pietersen. BRCA1-deficient mammary tumor cells are dependent on EZH2 expression and sensitive to Polycomb Repressive Complex 2-inhibitor 3-deazaneplanocin. A. Breast Cancer Res. 2009. Vol. 11. pp. R63'],\n",
       " 'matched_id': ['W322718260',\n",
       "  'W2098245740',\n",
       "  'W2737276581',\n",
       "  'W1983545974',\n",
       "  'W2133743991'],\n",
       " 'matched_doi': ['',\n",
       "  'https://doi.org/10.2106/jbjs.h.00416',\n",
       "  'https://doi.org/10.1186/s12885-017-3478-z',\n",
       "  'https://doi.org/10.1371/journal.pone.0098176',\n",
       "  'https://doi.org/10.1186/bcr2354'],\n",
       " 'matched_result': [{'first_author': 'Lichtenstein',\n",
       "   'journal': 'PubMed',\n",
       "   'title': 'Chondrosarcoma of Bone.',\n",
       "   'year': 1943},\n",
       "  {'first_author': 'Giuffrida',\n",
       "   'journal': 'Journal of Bone and Joint Surgery',\n",
       "   'title': 'Chondrosarcoma in the United States (1973 to 2003): An Analysis of 2890 Cases from the SEER Database',\n",
       "   'year': 2009},\n",
       "  {'first_author': 'Lhuissier',\n",
       "   'journal': 'BMC Cancer',\n",
       "   'title': 'Identification of an easy to use 3D culture model to investigate invasion and anticancer drug response in chondrosarcomas',\n",
       "   'year': 2017},\n",
       "  {'first_author': 'Girard',\n",
       "   'journal': 'PLoS ONE',\n",
       "   'title': '3-Deazaneplanocin A (DZNep), an Inhibitor of the Histone Methyltransferase EZH2, Induces Apoptosis and Reduces Cell Migration in Chondrosarcoma Cells',\n",
       "   'year': 2014},\n",
       "  {'first_author': 'Puppe',\n",
       "   'journal': 'Breast Cancer Research',\n",
       "   'title': 'BRCA1-deficient mammary tumor cells are dependent on EZH2 expression and sensitive to Polycomb Repressive Complex 2-inhibitor 3-deazaneplanocin A',\n",
       "   'year': 2009}],\n",
       " 'is_match_by_similarity': [False, True, True, True, True],\n",
       " 'matched_link': ['https://openalex.org/works?zoom=w322718260',\n",
       "  'https://openalex.org/works?zoom=w2098245740',\n",
       "  'https://openalex.org/works?zoom=w2737276581',\n",
       "  'https://openalex.org/works?zoom=w1983545974',\n",
       "  'https://openalex.org/works?zoom=w2133743991']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset_dict)\n",
    "preview_split = next(iter(dataset_dict.keys()))\n",
    "print(f\"Preview split: {preview_split}\")\n",
    "dataset_dict[preview_split][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de49342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0071ac1911450ba0a16bee0738fe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aaadc86d8048fea42b753731da5441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d58997b3f744355b8dc74f516d27969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d44648a73a64ac9a738d8382a41e574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0157370fd8418e83ff87d5116b94f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  148kB /  148kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33293219a60418484f62bd8dd1a8718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c2851118f0430a83c7fb1dc3bea38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcea04b02504138a948cb3eae07fc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e57f3da8be4e27a2543d5d6f0ac233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253eabf209be428f8aa1e13c638b63c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########|  243kB /  243kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5538176c598d48d9abd9d9e0d2102bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab49f46466cc4738aab17ace772a63a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024469b7dc8c413da8e673a8c4a3f4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eacdf53499c40f2be0c96471de1f5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddf41c49cf44a93b49181fd2f710f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                        : 100%|##########| 98.5kB / 98.5kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/yurui983/citation_linking/commit/73424b6b662e21e43c1a2a96329fcdb08ed556fe', commit_message='Upload dataset', commit_description='', oid='73424b6b662e21e43c1a2a96329fcdb08ed556fe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/yurui983/citation_linking', endpoint='https://huggingface.co', repo_type='dataset', repo_id='yurui983/citation_linking'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = os.environ.get(\"HF_TOKEN\") or getpass(\"Enter your Hugging Face token: \")\n",
    "login(token=hf_token, add_to_git_credential=True)\n",
    "dataset_dict.push_to_hub(\"yurui983/citation_linking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1818e",
   "metadata": {},
   "source": [
    "## Push to Argilla for annotation\n",
    "\n",
    "This section creates one Argilla dataset per provider split and uploads records for human annotation. Each record will include:\n",
    "\n",
    "- the original reference string\n",
    "- the matched id and a link to the matched result\n",
    "- a compact matched result summary (title, first_author, year, journal)\n",
    "\n",
    "The annotation questions are:\n",
    "1) Is the matched result correct? (true/false)\n",
    "2) If incorrect, provide the correct ID (text input).\n",
    "\n",
    "You will be prompted for Argilla API URL and API token to connect to your deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67312d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install argilla if not already installed (uncomment to run in notebook)\n",
    "# !pip install -U argilla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f57b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines_markdown = \"\"\"\n",
    "# Annotation Guidelines: Citation Linking\n",
    "\n",
    "## What the fields mean\n",
    "- ref_id: Internal identifier of the reference.\n",
    "- original_ref_string: The raw reference text extracted from the document.\n",
    "- matched_id: Provider-specific ID of the candidate match (or \"Not Found\").\n",
    "  - OpenAlex: W1234567890 (last segment of /works/W…)\n",
    "  - Wikidata: Q12345\n",
    "  - Matilda: last path segment in /work/<id>\n",
    "- matched_doi: DOI of the candidate match (if available).\n",
    "- matched_result: Compact summary of the candidate (title, first_author, year, journal).\n",
    "- is_match_by_similarity: Model’s heuristic guess (for context only).\n",
    "- matched_link: Link to view the candidate on the provider site.\n",
    "\n",
    "## What you need to do\n",
    "1) Check if the candidate is the same work as the reference.\n",
    "   - Compare title, first author surname, year, and DOI (if present).\n",
    "   - Use matched_link to verify details on the provider page.\n",
    "2) If the candidate is incorrect OR empty (matched_id = \"Not Found\" or no details shown), find the correct record in the same provider and paste its ID in correct_id.\n",
    "3) If you believe no record exists for this reference in this provider, select “No match”.\n",
    "\n",
    "## How to answer\n",
    "- Candidate is correct:\n",
    "  - is_match_correct = true\n",
    "  - No match = false\n",
    "  - correct_id = (leave blank)\n",
    "- Candidate is incorrect but correct record exists:\n",
    "  - is_match_correct = false\n",
    "  - No match = false\n",
    "  - correct_id = provider-specific ID (OpenAlex W…, Wikidata Q…, Matilda work id)\n",
    "- No record in this provider:\n",
    "  - is_match_correct = false\n",
    "  - No match = true\n",
    "  - correct_id = (leave blank)\n",
    "\n",
    "Notes:\n",
    "- Minor formatting/casing differences are fine; it must be the same work.\n",
    "- Provide only the ID (not a URL).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fed502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: citation_linking_openalex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending records...: 3batch [00:08,  2.79s/batch]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: citation_linking_matilda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending records...: 3batch [00:07,  2.45s/batch]                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset: citation_linking_wikidata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sending records...: 3batch [00:07,  2.58s/batch]                    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "try:\n",
    "    import argilla as rg\n",
    "except Exception:\n",
    "    raise\n",
    "\n",
    "ARGILLA_API_URL = os.environ.get(\"ARGILLA_API_URL\") or 'https://argilla-route-graphia-app1-staging.apps.bst2.paas.psnc.pl/'\n",
    "ARGILLA_API_TOKEN = os.environ.get(\"ARGILLA_API_TOKEN\") or 'argilla.apikey'\n",
    "\n",
    "client = rg.Argilla(api_key=ARGILLA_API_TOKEN, api_url=ARGILLA_API_URL)\n",
    "# 'ref_id', 'original_ref_string', 'matched_id', 'matched_doi', 'matched_result', 'is_match_by_similarity', 'matched_link'],\n",
    "\n",
    "settings = rg.Settings(\n",
    "        fields=[\n",
    "            rg.TextField(name=\"ref_id\", title=\"Reference ID\", description=\"The ID of the original reference.\"),\n",
    "            rg.TextField(name=\"original_ref_string\", title=\"Reference String\", description=\"The original reference string extracted from the document.\"),\n",
    "            rg.TextField(name=\"matched_id\", title=\"Matched ID\", description=\"The ID of the matched record from the external provider.\"),\n",
    "            rg.TextField(name=\"matched_doi\", title=\"Matched DOI\", description=\"The DOI of the matched record from the external provider.\"),\n",
    "            rg.TextField(name=\"matched_result\", title=\"Matched Result\", description=\"The result of the matching process.\",use_markdown=True),\n",
    "            rg.TextField(name=\"is_match_by_similarity\", title=\"Is Match by Similarity\", description=\"Indicates if the match was found by similarity.\"),\n",
    "            rg.TextField(name=\"matched_link\", title=\"Matched Link\", use_markdown=True, description=\"The link to the matched record from the external provider.\"),\n",
    "        ],\n",
    "        guidelines=guidelines_markdown,\n",
    "        questions=[\n",
    "            rg.LabelQuestion(\n",
    "                name=\"is_match_correct\",\n",
    "                title=\"Is the matched result correct?\",\n",
    "                labels=[\"true\", \"false\"],\n",
    "                description=\"Select 'true' if the candidate matched record corresponds to the same publication as the reference (matching title, first author and year). Otherwise select 'false'.\",\n",
    "                required=True,\n",
    "            ),  \n",
    "            rg.TextQuestion(\n",
    "                name=\"correct_id\",\n",
    "                title=\"If incorrect, provide the correct ID (only id)\",\n",
    "                description=\"When the candidate is incorrect, type the provider-specific identifier of the correct match (e.g., OpenAlex id like W1234567890). Leave blank if 'true'.\",\n",
    "                required=False,\n",
    "            ),\n",
    "            rg.LabelQuestion(\n",
    "                name=\"This reference has no match\",\n",
    "                title=\"Does this reference have no match?\",\n",
    "                labels=[\"true\", \"false\"],\n",
    "                description=\"Select 'true' if the reference has no match in the this provider. Otherwise select 'false'.\",\n",
    "                required=True,\n",
    "            ),\n",
    "            ]\n",
    "            \n",
    ")\n",
    "\n",
    "# Helper to format matched_result into a readable string\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "\n",
    "def matched_result_to_markdown_json(m: Optional[Dict[str, Any]]) -> str:\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    \n",
    "    json_str = '```json\\n' + json.dumps(m, indent=2) + '\\n```'\n",
    "    return json_str\n",
    "\n",
    "# Define the Argilla dataset schema (fields/questions)\n",
    "# from argilla.client.models import TextField, TextAreaField, LabelQuestion, ResponseSchema, FieldSchema\n",
    "\n",
    "def matched_link_to_markdown(m: Optional[str]) -> str:\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    return f\"[{m}]({m})\"\n",
    "\n",
    "dataset_dict = load_dataset(\"yurui983/citation_linking\")\n",
    "\n",
    "for split_name, ds in dataset_dict.items():\n",
    "\n",
    "    dataset_name = f\"citation_linking_{split_name}\"\n",
    "\n",
    "    #delete existing dataset if exists\n",
    "    # dataset = rg.Dataset(name=dataset_name)\n",
    "    # dataset.delete()\n",
    "    print(\"Creating dataset:\", dataset_name)\n",
    "    \n",
    "    dataset = rg.Dataset(name=dataset_name, settings=settings)\n",
    "    dataset.create()\n",
    "    hf_dataset = dataset_dict[split_name]\n",
    "    records_to_log = []\n",
    "    for ex in hf_dataset:\n",
    "        matched_raw = ex.get(\"matched_result\") or {}\n",
    "        # If matched_result is a dict with the summary fields, convert to text\n",
    "        matched_text = (\n",
    "            matched_result_to_markdown_json(matched_raw)\n",
    "            if isinstance(matched_raw, dict)\n",
    "            else str(matched_raw or \"\")\n",
    "        )\n",
    "\n",
    "        is_match_val = ex.get(\"is_match_by_similarity\")\n",
    "        # Argilla TextField expects string (or list/dict depending on schema); convert bool to string\n",
    "        if isinstance(is_match_val, bool):\n",
    "            is_match_str = \"true\" if is_match_val else \"false\"\n",
    "        # else:\n",
    "        #     is_match_str = str(is_match_val) if is_match_val is not None else \"\"\n",
    "\n",
    "        record = {\n",
    "            \"ref_id\": ex.get(\"ref_id\") or \"\",\n",
    "            \"original_ref_string\": ex.get(\"original_ref_string\") or \"\",\n",
    "            \"matched_id\": ex.get(\"matched_id\") or \"Not Found\",\n",
    "            \"matched_doi\": ex.get(\"matched_doi\") or \"\",\n",
    "            \"matched_result\": matched_text,\n",
    "            \"is_match_by_similarity\": is_match_str,\n",
    "            \"matched_link\": ex.get(\"matched_link\") or \"\",\n",
    "            # include ref_id as metadata so annotators / export scripts can trace back\n",
    "            \"metadata\": {\"ref_id\": ex.get(\"ref_id\")},\n",
    "        }\n",
    "        records_to_log.append(record)\n",
    "\n",
    "    # Log records (batch)\n",
    "    # ds.records.log(records=records_to_log)\n",
    "    dataset.records.log(records=records_to_log)\n",
    "\n",
    "    # break  # Only do one split for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba45bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citation_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
