{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pdf_extractors import ExtractorFactory\n",
    "import pandas as pd\n",
    "import json\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCITE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total references: 10171\n"
     ]
    }
   ],
   "source": [
    "def get_sample_data(pdf_df, references_data, n_samples=5):\n",
    "    \"\"\"Display sample data for verification\"\"\"\n",
    "    print(f\"\\n=== SAMPLE PDF DATA ===\")\n",
    "    if not pdf_df.empty:\n",
    "        print(pdf_df.sample(n_samples).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n=== SAMPLE REFERENCES DATA ===\")\n",
    "    if references_data:\n",
    "        sample_keys = list(references_data.keys())[:n_samples]\n",
    "        for i, file_id in enumerate(sample_keys):\n",
    "            ref_data = references_data[file_id]\n",
    "            print(f\"Paper {i+1} (ID: {file_id}):\")\n",
    "            print(f\"  Number of references: {len(ref_data['references'])}\")\n",
    "            print(f\"  First few references:\")\n",
    "            for j, ref in enumerate(ref_data['references'][:3]):\n",
    "                print(f\"    {j+1}. {ref}\")\n",
    "            if len(ref_data['references']) > 3:\n",
    "                print(f\"    ... and {len(ref_data['references']) - 3} more\")\n",
    "            print()\n",
    "\n",
    "\n",
    "pdf_df = pd.read_csv(\"EXgoldstandard/Goldstandard_EXparser/pdf_files_info.csv\")\n",
    "references_data = json.load(open(\"EXgoldstandard/Goldstandard_EXparser/all_references.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "total_references = sum(len(data[\"references\"]) for data in references_data.values())\n",
    "print('Total references:', total_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE PDF DATA ===\n",
      " file_id  filename  class lang                                                                                                                          file_path\n",
      "   34481 34481.pdf      1   de      EXgoldstandard/Goldstandard_EXparser/1-German_papers/1-German_papers(with_reference_section_at_end_of_paper)/1-pdfs/34481.pdf\n",
      "   20011 20011.pdf      1   de      EXgoldstandard/Goldstandard_EXparser/1-German_papers/1-German_papers(with_reference_section_at_end_of_paper)/1-pdfs/20011.pdf\n",
      "   39854 39854.pdf      1   de      EXgoldstandard/Goldstandard_EXparser/1-German_papers/1-German_papers(with_reference_section_at_end_of_paper)/1-pdfs/39854.pdf\n",
      "   19396 19396.pdf      3   de EXgoldstandard/Goldstandard_EXparser/1-German_papers/3-German_papers(with_reference_in_footnote_and_end_of_paper)/1-pdfs/19396.pdf\n",
      "   52971 52971.pdf      1   en    EXgoldstandard/Goldstandard_EXparser/2-English_papers/1-English_papers(with_reference_section_at_end_of_paper)/1-pdfs/52971.pdf\n",
      "\n",
      "=== SAMPLE REFERENCES DATA ===\n",
      "Paper 1 (ID: 26236):\n",
      "  Number of references: 14\n",
      "  First few references:\n",
      "    1. Statistisches Bundesamt (1978a): Volkszählung vom 27. Mai 1970. Methodische und praktische Vorbereitung sowie Durchführung der Volkszählung 1970. Fachserie 1 Heft 25. Stuttgart/Mainz: Kohlhammer.\n",
      "    2. Statistisches Bundesamt (1978b): Volkszählung vom 27. Mai 1970. Untersuchungen zur Methode und Genauigkeit der Volkszählung 1970. Fachserie 1 Heft 26. Stuttgart/Mainz: Kohlhammer.\n",
      "    3. \"Statistisches Bundesamt (1972): Ausgewählte Strukturdaten für Bund und Länder. Fachserie A: Bevölkerung und Kultur. Volkszählung vom 27. Mai 1970, Heft 1.\"\n",
      "    ... and 11 more\n",
      "\n",
      "Paper 2 (ID: 45544):\n",
      "  Number of references: 40\n",
      "  First few references:\n",
      "    1. Arends-Tòth, J. / Van de Vijver, F. J. (2003): Multiculturalism and acculturation: Views of Dutch and Turkish-Dutch. European Journal of Social Psychology 33(2), S. 249-266.\n",
      "    2. Arends-Tóth, J. / Van de Vijver, F. J. (2006a): Assessment of psychological acculturation. In: Sam, D. L. / Berry, J. W. (Hrsg.): The camebridge handbook of acculturation psychology. New York: Cambridge University Press, S. 142-162.\n",
      "    3. Arends-Tóth, J. / Van de Vijver, F. J. (2006b): Issues in the conceptualization and assessment of acculturation. In: Bornstein, M. H. / Cote, L. R. (Hrsg.): Acculturation and parent child relationships: Measurement and development. Mahwah, NJ: Erlbaum, S. 33-62.\n",
      "    ... and 37 more\n",
      "\n",
      "Paper 3 (ID: 11129):\n",
      "  Number of references: 33\n",
      "  First few references:\n",
      "    1. \"Arnold, Michael; Strehl, Rüdiger, 2000: Wie kommen Innovationen ins DRG-System? (Die Steuerungsfunktion der Bundesauschüsse), in: Michael Arnold; Martin Litsch; Henner Schellenschmidt (Hg.): Krankenhaus-Report 2000. Schwerpunkt: Vergütungsreform mit DRGs. Stuttgart: Schattauer, 159-171.\"\n",
      "    2. \"Beske, Fritz, 2001: Neubestimmung und Finanzierung des Leistungskatalogs der gesetzlichen Krankenversicherung: Kieler Konzept – Paradigmenwechsel im Gesundheitswesen. Berlin u.a.: Quintessenz.\"\n",
      "    3. \"Borchert, Günter, 1999: „Sicherung der Verbindlichkeit untergesetzlicher Normen im Krankenversicherungsrecht“, Die Krankenversicherung 51: 273-275.\"\n",
      "    ... and 30 more\n",
      "\n",
      "Paper 4 (ID: 38381):\n",
      "  Number of references: 23\n",
      "  First few references:\n",
      "    1. Baron, Ch. und Ch. Lassalle. 1915. Dictionnaire des communes administratif & militaire. 12. Aufl. Paris: Charles-Lavauzelle.\n",
      "    2. Blumenauer, Elke. 2000. Journalismus zwischen Pressefreiheit und Zensur. Die Augsburger „Allgemeine Zeitung“ im Karlsbader System (1818-1848) (Medien in Geschichte und Gegenwart, Bd. 14). Köln: Böhlau.\n",
      "    3. Bohrmann, Hans und Gabriele Toepser-Ziegert, eds. 2003. Mikrofilmarchiv der deutschsprachigen Presse e.V.11. Bestandsverzeichnis. Berlin: Vistas.\n",
      "    ... and 20 more\n",
      "\n",
      "Paper 5 (ID: 24743):\n",
      "  Number of references: 58\n",
      "  First few references:\n",
      "    1. Arnold, T./Stuewe, G., 1993: Jugend - Gewalt - Gangs der zweiten Migrantengeneration. Sozialmagazin 18: 40-47.\n",
      "    2. Aster, R./Kuckartz, U., 1988: Jugend und Schule. Eine Sekundäranalyse schulspezifischer Fragen der Shell-Studie „Jugendliche und Erwachsene `85“. Zeitschrift für Sozialisationsforschung und Erziehungssoziologie 8: 200-212.\n",
      "    3. Baacke, D., 1993: Jugend und Jugendkulturen. Darstellung und Deutung. Weinheim, München: Juventa.\n",
      "    ... and 55 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sample_data(pdf_df, references_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_EXTRACTION_PROMPT_SYS = \"\"\"You are an expert in scholarly references and citations. You help the user to extract citation data from scientific works.\"\"\"\n",
    "\n",
    "REFERENCE_EXTRACTION_PROMPT_USER = \"\"\"\n",
    "Extract all references from the given text. Output each reference as plain text, one reference per line. Only output the reference text, nothing else. Do not include any explanations, numbering, or additional formatting.\n",
    "\n",
    "TEXT: <<<{input_text}>>>\n",
    "\n",
    "## Example Usage\n",
    "**Input Text:**\n",
    "This paper builds on previous work (Smith et al., 2020; Jones, 2019). According to recent studies...\n",
    "\n",
    "References:\n",
    "1. Smith, J., Brown, A., & Wilson, C. (2020). Machine learning approaches in natural language processing. Journal of AI Research, 15(3), 245-267.\n",
    "2. Jones, M. (2019). Deep learning fundamentals. MIT Press.\n",
    "3. Davis, R., & Lee, S. (2021). Neural networks and their applications. Nature Machine Intelligence, 3(2), 112-125.\n",
    "\n",
    "**Expected Output:**\n",
    "Smith, J., Brown, A., & Wilson, C. (2020). Machine learning approaches in natural language processing. Journal of AI Research, 15(3), 245-267.\n",
    "Jones, M. (2019). Deep learning fundamentals. MIT Press.\n",
    "Davis, R., & Lee, S. (2021). Neural networks and their applications. Nature Machine Intelligence, 3(2), 112-125.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aron, Raymond/Dominique Schnapper (1988): Power, modernity, and sociology : selected sociological writings. Aldershot, Hants, England Brookfield, Vt., USA: E. Elgar ;\n",
      "Collins, Harry (2004): Gravity's shadow : the search for gravitational waves. Chicago: University of Chicago Press.\n",
      "Collins, Harry M. (1981): Stages in the Empirical Programme of Relativism. In: Social Studies of Science, 11 S. 3-10.\n",
      "Collins, Harry M. (1983): An Empirical Relativist Programme in the Sociology of Scientific Knowledge. In: K.D. Knorr-Cetina/M. Mulkay (Hrsg.): Science observed. Perspectives on the social study of science. London. Sage: S: 85-113\n",
      "Collins, Harry M. (1985): Changing order : replication and induction in scientific practice, London u.a.: Sage.\n",
      "Collins, Harry/Trevor Pinch (1999): Golem der Forschung (Der). Wie unsere Wissenschaft die Natur erfindet. Berlin: Berlin Verlag.\n",
      "Dosi, Giovanni (1982): Technological Paradigms and Technological Trajectories. A Suggested Interpretation of the Determinants and Directions of Technical Change. In: Research Policy, 11 S. 147-162.\n",
      "Esser, Hartmut (1993): Soziologie. Allgemeine Grundlagen, Frankfurt/Main u.a.: Campus. Gower Pub. Co.\n",
      "Hacking, Ian (1999): Was heißt 'soziale Konstruktion'? Zur Konjunktur einer Kampfvokabel in der Wissenschaft, Frankfurt/Main: Fischer.\n",
      "Kuhn, Thomas S. (1976): Die Struktur wissenschaftlicher Revolutionen. Frankfurt/Main: Suhrkamp.\n",
      "Luhmann, Niklas (1990): Die Wissenschaft der Gesellschaft, Frankfurt/Main: Suhrkamp.\n",
      "MacKenzie, Donald (1989): From Kwajalein to Armageddon? Testing and the Social Construction of Missile Accuracy. In: D.G.e. al. (Hrsg.): S: 409-435\n",
      "Meyer, Uli (2004): Die Kontroverse um Neuronale Netze. Zur sozialen Aushandlung der wissenschaftlichen Relevanz eines Forschugnsansatzes. Wiesbaden: Deutscher Universitätsverlag.\n",
      "Minsky, Marvin Lee/Seymour Papert (1969): Perceptrons; an introduction to computational geometry. Cambridge, Mass.,: MIT Press.\n",
      "Pinch, Trevor (1996): The Social Construction of Technology: A Review. In: R. Fox/P. Scranton (Hrsg.): Technological Change: Methods and Themes in the History of Technology. Amsterdam u.a.: Harwood. S: 17-35\n",
      "Pinch, Trevor J./Wiebe E. Bijker (1984): The Social Construction of Facts and Artefacts: Or How the Sociology of Science and the Sociology of Technology might Benefit Each Other. In: Social Studies of Science, 14 S. 399-441.\n",
      "Pinch, Trevor J./Wiebe E. Bijker (1987): The Social Construction of Facts and Artifacts: Or How the Sociology of Science and the Sociology of Technology Might Benefit Each Other, in: W. E. Bijker et al. (Hrsg.), S. 17-50.\n",
      "Schulz-Schaeffer, Ingo (1999): Technik und die Dualität von Ressourcen und Routinen, in: Zeitschrift für Soziologie 28(6), S. 409-428.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "endpoint = 'https://api.deepseek.com/v1'\n",
    "model = 'deepseek-chat'\n",
    "api_key = 'sk-282f6b9a54b64bd98bfcd85c0c8f5aab' # deepseek\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint,\n",
    ")\n",
    "\n",
    "filepath = 'EXgoldstandard/Goldstandard_EXparser/all_pdfs/1181.pdf'\n",
    "\n",
    "extractor = ExtractorFactory.create(\"pymupdf\")\n",
    "result = extractor.extract(filepath)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": REFERENCE_EXTRACTION_PROMPT_SYS},\n",
    "        {\"role\": \"user\", \"content\": REFERENCE_EXTRACTION_PROMPT_USER.format(input_text=result)}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aron, Raymond/Dominique Schnapper (1988): Power, modernity, and sociology : selected sociological writings. Aldershot, Hants, England Brookfield, Vt., USA: E. Elgar ;',\n",
       " \"Collins, Harry (2004): Gravity's shadow : the search for gravitational waves. Chicago: University of Chicago Press.\",\n",
       " 'Collins, Harry M. (1981): Stages in the Empirical Programme of Relativism. In: Social Studies of Science, 11 S. 3-10.',\n",
       " 'Collins, Harry M. (1983): An Empirical Relativist Programme in the Sociology of Scientific Knowledge. In: K.D. Knorr-Cetina/M. Mulkay (Hrsg.): Science observed. Perspectives on the social study of science. London. Sage: S: 85-113',\n",
       " 'Collins, Harry M. (1985): Changing order : replication and induction in scientific practice, London u.a.: Sage.',\n",
       " 'Collins, Harry/Trevor Pinch (1999): Golem der Forschung (Der). Wie unsere Wissenschaft die Natur erfindet. Berlin: Berlin Verlag.',\n",
       " 'Dosi, Giovanni (1982): Technological Paradigms and Technological Trajectories. A Suggested Interpretation of the Determinants and Directions of Technical Change. In: Research Policy, 11 S. 147-162.',\n",
       " 'Esser, Hartmut (1993): Soziologie. Allgemeine Grundlagen, Frankfurt/Main u.a.: Campus. Gower Pub. Co.',\n",
       " \"Hacking, Ian (1999): Was heißt 'soziale Konstruktion'? Zur Konjunktur einer Kampfvokabel in der Wissenschaft, Frankfurt/Main: Fischer.\",\n",
       " 'Kuhn, Thomas S. (1976): Die Struktur wissenschaftlicher Revolutionen. Frankfurt/Main: Suhrkamp.',\n",
       " 'Luhmann, Niklas (1990): Die Wissenschaft der Gesellschaft, Frankfurt/Main: Suhrkamp.',\n",
       " 'MacKenzie, Donald (1989): From Kwajalein to Armageddon? Testing and the Social Construction of Missile Accuracy. In: D.G.e. al. (Hrsg.): S: 409-435',\n",
       " 'Meyer, Uli (2004): Die Kontroverse um Neuronale Netze. Zur sozialen Aushandlung der wissenschaftlichen Relevanz eines Forschugnsansatzes. Wiesbaden: Deutscher Universitätsverlag.',\n",
       " 'Minsky, Marvin Lee/Seymour Papert (1969): Perceptrons; an introduction to computational geometry. Cambridge, Mass.,: MIT Press.',\n",
       " 'Pinch, Trevor (1996): The Social Construction of Technology: A Review. In: R. Fox/P. Scranton (Hrsg.): Technological Change: Methods and Themes in the History of Technology. Amsterdam u.a.: Harwood. S: 17-35',\n",
       " 'Pinch, Trevor J./Wiebe E. Bijker (1984): The Social Construction of Facts and Artefacts: Or How the Sociology of Science and the Sociology of Technology might Benefit Each Other. In: Social Studies of Science, 14 S. 399-441.',\n",
       " 'Pinch, Trevor J./Wiebe E. Bijker (1987): The Social Construction of Facts and Artifacts: Or How the Sociology of Science and the Sociology of Technology Might Benefit Each Other, in: W. E. Bijker et al. (Hrsg.), S. 17-50.',\n",
       " 'Schulz-Schaeffer, Ingo (1999): Technik und die Dualität von Ressourcen und Routinen, in: Zeitschrift für Soziologie 28(6), S. 409-428.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references_data['1181']['references']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'f1_score': 1.0,\n",
       " 'avg_levenshtein_distance': np.float64(0.0)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def calculate_matrix(references_data, response_list):\n",
    "    \"\"\"\n",
    "    Calculate Precision, Recall, F1 and Levenshtein distance for PDF reference extraction.\n",
    "    \n",
    "    Args:\n",
    "        references_data: List of ground truth references (strings)\n",
    "        response_list: List of extracted references (strings)\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing precision, recall, f1_score, and avg_levenshtein_distance\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def normalize_text(text):\n",
    "        \"\"\"Basic text normalization\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        return text.strip()\n",
    "    \n",
    "    # Normalize inputs and remove empty strings\n",
    "    gt_refs = [normalize_text(ref) for ref in references_data if normalize_text(ref)]\n",
    "    pred_refs = [normalize_text(ref) for ref in response_list if normalize_text(ref)]\n",
    "    \n",
    "    n_gt = len(gt_refs)\n",
    "    n_pred = len(pred_refs)\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if n_gt == 0 and n_pred == 0:\n",
    "        return {\n",
    "            'precision': 1.0,\n",
    "            'recall': 1.0,\n",
    "            'f1_score': 1.0,\n",
    "            'avg_levenshtein_distance': 0.0\n",
    "        }\n",
    "    \n",
    "    if n_gt == 0:\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'avg_levenshtein_distance': float('inf')\n",
    "        }\n",
    "    \n",
    "    if n_pred == 0:\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'avg_levenshtein_distance': float('inf')\n",
    "        }\n",
    "    \n",
    "    # Create distance matrix\n",
    "    distance_matrix = np.zeros((n_gt, n_pred))\n",
    "    \n",
    "    for i, gt_ref in enumerate(gt_refs):\n",
    "        for j, pred_ref in enumerate(pred_refs):\n",
    "            distance_matrix[i, j] = levenshtein_distance(gt_ref, pred_ref)\n",
    "    \n",
    "    # Find optimal assignment using Hungarian algorithm (minimize total distance)\n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix)\n",
    "    \n",
    "    # Define similarity threshold based on normalized distance\n",
    "    SIMILARITY_THRESHOLD = 0.8  # Accept matches with normalized similarity >= 0.8\n",
    "    \n",
    "    matched_pairs = 0\n",
    "    total_distance = 0\n",
    "    \n",
    "    for i, j in zip(row_indices, col_indices):\n",
    "        distance = distance_matrix[i, j]\n",
    "        max_len = max(len(gt_refs[i]), len(pred_refs[j]))\n",
    "        normalized_similarity = 1 - (distance / max_len) if max_len > 0 else 1.0\n",
    "        \n",
    "        if normalized_similarity >= SIMILARITY_THRESHOLD:\n",
    "            matched_pairs += 1\n",
    "            total_distance += distance\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = matched_pairs / n_pred\n",
    "    recall = matched_pairs / n_gt\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    avg_levenshtein_distance = total_distance / matched_pairs if matched_pairs > 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1_score': round(f1_score, 4),\n",
    "        'avg_levenshtein_distance': round(avg_levenshtein_distance, 2) if avg_levenshtein_distance != float('inf') else float('inf')\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "calculate_matrix(references_data['1181']['references'], response.choices[0].message.content.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 5/351 [02:16<2:37:58, 27.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: format error: No default Layer config\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/351 [03:39<4:25:13, 46.13s/it]"
     ]
    }
   ],
   "source": [
    "# run on whole excite dataset\n",
    "extractor = ExtractorFactory.create(\"pymupdf\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "response_list = []\n",
    "matrix = []\n",
    "for id in tqdm(pdf_df['file_id']):\n",
    "    filepath = f'EXgoldstandard/Goldstandard_EXparser/all_pdfs/{id}.pdf'\n",
    "    result = extractor.extract(filepath)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": REFERENCE_EXTRACTION_PROMPT_SYS},\n",
    "            {\"role\": \"user\", \"content\": REFERENCE_EXTRACTION_PROMPT_USER.format(input_text=result)}\n",
    "        ]\n",
    "    )\n",
    "    response_list.append({'id': id, 'response': response.choices[0].message.content})\n",
    "    matrix.append(calculate_matrix(references_data[str(id)]['references'], response.choices[0].message.content.split('\\n')))\n",
    "\n",
    "\n",
    "# save response_list\n",
    "with open('response_list.json', 'w') as f:\n",
    "    json.dump(response_list, f)\n",
    "\n",
    "\n",
    "# summarize matrix and print precision, recall, f1_score, avg_levenshtein_distance\n",
    "matrix_df = pd.DataFrame(matrix)\n",
    "print(matrix_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
