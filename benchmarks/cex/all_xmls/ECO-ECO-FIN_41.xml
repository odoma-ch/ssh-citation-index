<?xml version='1.0' encoding='UTF-8'?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Quantifying information and uncertainty</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2018-04">April 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Alexander</forename><surname>Frankel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emir</forename><surname>Kamenica</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Quantifying information and uncertainty</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-04">April 2018</date>
						</imprint>
					</monogr>
					<idno type="MD5">ADDE076B32AFA70B64C3D957C7E1AE47</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>JEL classification: D80</term>
					<term>D83 value of information</term>
					<term>Bregman divergences</term>
					<term>entropy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We examine ways to measure the amount of information generated by a piece of news and the amount of uncertainty implicit in a given belief. Say a measure of information is valid if it corresponds to the value of news in some decision problem. Say a measure of uncertainty is valid if it corresponds to expected utility loss from not knowing the state in some decision problem. We axiomatically characterize all valid measures of information and uncertainty. We show that if a measure of information and uncertainty arise from the same decision problem, then the two are coupled in that the expected reduction in uncertainty always equals the expected amount of information generated. We provide explicit formulas for the measure of information that is coupled with any given measure of uncertainty and vice versa. Finally, we show that valid measures of information are the only payment schemes that never provide incentives to delay information revelation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Suppose we observe some pieces of news. How might we quantify the amount of information contained in each piece? One desideratum might be that the measure should correspond to the instrumental value of information for some decision problem. Another approach would be to specify that the measure should satisfy the following properties: (i) news cannot contain a negative amount of information, (ii) news that does not affect beliefs generates no information, and (iii) the order in which the news is read does not, on average, change the total amount of information generated. The first result of this paper is that these two approaches are equivalent. A measure of information reflects instrumental value for some decision-maker if and only if it satisfies the three aforementioned properties. We call such measures of information valid.</p><p>A related question is: how might we quantify uncertainty of a belief? Again, one approach would be to measure uncertainty by its instrumental cost, i.e., by the extent to which it reduces a decision-makerâ€™s utility relative to an omniscient benchmark. Another approach would couple the measure of uncertainty to some valid measure of information and insist that, on average, observing news reduces uncertainty to the extent that it generates information. We show that these two approaches are equivalent: a (suitably normalized) measure of uncertainty reflects the instrumental cost for some decision-maker if and only if the expected reduction in uncertainty always equals the expected amount of information generated (by a valid measure). We call such measures of uncertainty valid. In fact, every concave function that is zero at degenerate beliefs is a valid measure of uncertainty.</p><p>These results have various implications. First, they tell us that some seemingly sensible ways of measuring information, such as the Euclidean distance between the prior and the posterior, are not valid (under our definition of this term). In fact, no metric is valid: there does not exist a decision problem with an instrumental value of information that is a metric on beliefs. Second, our results provide novel decision-theoretic foundations for standard measures of information and uncertainty, such as Kullback-Leibler divergence and entropy or quadratic distance and variance. Finally, our results introduce a notion of â€œcouplingâ€ between measures of information and measures of uncertainty that reflects the fact Kullback-Leibler divergence complements entropy while quadratic distance complements variance. In fact, every valid measure of information is coupled with a unique valid measure of uncertainty (and vice versa), but we cannot mix and match. We also derive a functional form that pins down the measure of uncertainty coupled with a given measure of information and vice versa. These functional forms in turn provide an easy way of verifying whether a given measure of information is valid.</p><p>In contrast to much of the existing literature, we focus on ex post rather than ex ante measures of information. Taking a decision problem as given, it is straightforward to quantify the ex ante instrumental value of a Blackwell experiment, i.e., of a news generating process. <ref type="foot" target="#foot_0">foot_0</ref> The literature on rational inattention (e.g., <ref type="bibr" target="#b27">Sims 2003)</ref> also takes the ex ante perspective and associates the cost of information acquisition/processing with the expected reduction in entropy. The cost functions used in the rational inattention models have been generalized along a number of dimensions, <ref type="foot" target="#foot_1">foot_1</ref> but these generalizations typically still assume that the cost of an experiment is proportional to the expected reduction of some measure of uncertainty. <ref type="foot" target="#foot_2">foot_2</ref> Such cost functions inherently take an ex ante perspective since it is always possible that entropy (or any other measure of uncertainty) increases after some piece of news. Our approach maintains the feature that the ex ante amount of information coincides with the ex ante reduction in uncertainty, but in contrast to existing work, we ensure that the quantity of information generated is always positive, even from the ex post perspective.</p><p>Our approach, which links measures of information and uncertainty to underlying decision problems, introduces a natural notion of equivalence of decision problems (or collections of decision problems). We say two collections of decision problems are equivalent if they induce the same measure of uncertainty. <ref type="foot" target="#foot_3">foot_3</ref> We show that, when the state space is binary, every decision problem is equivalent to a collection of simple decision problems, i.e., problems where the decision-maker needs to match a binary action to the state. Finally, we establish that the measures of information we term valid coincide with the set of incentive-compatible payment schemes in a class of dynamic information-elicitation environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Set-up</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The informational environment</head><p>There is a finite state space Î© = {1, ..., n} with a typical state denoted Ï‰. A belief q is a distribution on Î© that puts weight q Ï‰ on the state Ï‰. We denote a belief that is degenerate on Ï‰ by Î´Ï‰ .</p><p>Information is generated by signals. We follow the formalization of <ref type="bibr" target="#b19">Green and Stokey (1978)</ref> and <ref type="bibr" target="#b16">Gentzkow and Kamenica (2017)</ref> and define a signal Ï€ as a finite partition of Î© Ã— [0, 1] s.t. Ï€ âŠ‚ S, where S is the set of non-empty Lebesgue-measurable subsets of Î© Ã— [0, 1]. We refer to an element s âˆˆ S as a signal realization. The interpretation is that a random variable x drawn uniformly from [0, 1] determines the signal realization conditional on the state; the probability of observing s âˆˆ Ï€ in Ï‰ is the Lebesgue measure of {x âˆˆ [0, 1] | (Ï‰, x) âˆˆ s}. As a notational convention, we let Î± denote the S-valued random variable induced by signal Ï€Î±.</p><p>Given a prior q, we denote the posterior induced by signal realization s by q (s). <ref type="foot" target="#foot_4">foot_4</ref> Observing realizations from both Ï€Î± and Ï€Î² induces the posterior q (Î± âˆ© Î²) since it reveals that (Ï‰, x) âˆˆ Î± âˆ© Î². We denote the signal that is equivalent to observing both Ï€Î± and Ï€Î² by Ï€Î± âˆ¨ Ï€Î² . <ref type="foot" target="#foot_5">foot_5</ref> For any signal Ï€Î± , we have E [q (Î±)] = q. <ref type="foot" target="#foot_6">foot_6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Decision problems</head><p>A decision problem D = (A, u) specifies a compact action set A and a continuous utility function u : A Ã— Î© â†’ R âˆª {âˆ’âˆ}. <ref type="foot" target="#foot_7">foot_7</ref> Given a decision problem D = (A, u), a value of information for D, denoted vD : âˆ† (Î©) Ã— âˆ† (Î©) â†’ R, is given by <ref type="foot" target="#foot_8">foot_8</ref></p><formula xml:id="formula_0">vğ’Ÿ(p,q) = ğ”¼p[u(a*(p),Ï‰)] âˆ’ ğ”¼p[u(a*(q),Ï‰)]</formula><p>where for belief q, a * (q) âˆˆ arg max aâˆˆA E q [u (a, Ï‰)].<ref type="foot" target="#foot_9">foot_9</ref> From the perspective of an agent with belief p, the payoff to a * (q) is E p [u (a * (q) , Ï‰)] whereas the payoff from taking the "correct" action given this belief is max aâˆˆA E p [u (a, Ï‰)]. Thus, v D (p, q) captures the ex post value of updating beliefs from q to p for a decision-maker who faces the decision problem D.<ref type="foot" target="#foot_10">foot_10</ref> If u is denominated in money, we can think of v D (p, q) as the greatest price at which the decision-maker could have purchased a signal that moved her belief from q to p such that she does not regret the purchase.<ref type="foot" target="#foot_11">foot_11</ref> Another interpretation of v D (p, q) is the instrumental loss from believing q when available data indicates p, as in models of belief-based utility that emphasize potential optimality of inaccurate beliefs (e.g., <ref type="bibr" target="#b10">Caplin and Leahy 2001,</ref><ref type="bibr" target="#b6">Brunnermeier and Parker 2005)</ref>.</p><p>The cost of uncertainty for D = (A, u) is</p><formula xml:id="formula_1">C D (q) = E q max a u (a, Ï‰) -max a E q [u (a, Ï‰)]</formula>.<p>The term E q [max a [u (a, Ï‰)]] is the expected payoff to the decision-maker if she were to learn the true state of the world before taking the action. The term max a [E q [u (a, Ï‰)]] is the expected payoff from the action that is optimal given belief q. Thus, the cost of uncertainty simply reflects how much lower the decision-maker's payoff is because she does not know the state of the world. This function is sometimes also called the expected value of perfect information.</p><p>Example 1. (Simple decision problem) Consider a decision problem with two actions a âˆˆ {0,1}, each of which is optimal in the corresponding state of the world Ï‰ âˆˆ {0,1}. We call such a problem simple. Normalizing the payoff of a=0 to zero in both states, a=1 is an optimal action if qu(1,1) + (1-q)u(1,0) â‰¥ 0, i.e., q â‰¥ r â‰¡ -u(1,0)/(u(1,1)-u(1,0)), where q denotes probability of Ï‰=1. We can further normalize the denominator u(1,1)-u(1,0) to 1, which yields utility function uÊ³ given by uÊ³(1,1)=1-r and uÊ³(1,0)=-r (with uÊ³(0,0)=uÊ³(0,1)=0). Thus, every simple decision problem is characterized by some r âˆˆ [0,1] and is denoted ğ’ŸÊ³..</p><p>Any value of information for ğ’ŸÊ³ equals |p-r| if r âˆˆ (min{p,q}, max{p,q}) (i.e., r is strictly between p and q) and zero if r &gt; max{p,q} or r &lt; min{p,q}. To see this, note that if r is not between p and q, the optimal action does not change so the value of information is zero. If q &lt; r &lt; p, the optimal action switches from 0 to 1, and the value of information is pu(1,1) + (1-p)u(1,0) = (p-r)u(1,1) + ((1-p)-(1-r))u(1,0) = (p-r)(u(1,1)-u(1,0)) = p-r. Likewise, if p &lt; r &lt; q, the optimal action switches from 1 to 0, and the value of information is (r-p). Thus, when r is between p and q, value of information is proportional to |p-r|. When q=r, we have flexibility in specifying the value of information since it depends on the way the decision-maker breaks her indifference. For concreteness, we suppose the decision-maker takes the two actions with equal probability, which yields the value of |p-r|/2. Hence, a value of information for ğ’ŸÊ³ is vÊ³(p,q) = |p-r| if r âˆˆ (min{p,q}, max{p,q}), |p-r|/2 if r=q, 0 otherwise. Note that, under vÊ³, belief movements that are "similar" do not necessarily generate similar value: if the cutoff belief is r = 0.5, moving from 0.49 to 0.9 generates much more value than moving from 0.51 to 0.9 since the former changes the action to the ex post optimal one whereas the latter leaves the action unchanged.</p> <p>The cost of uncertainty for problem ğ’ŸÊ³ is the triangular function CÊ³(q) = q(1-r) if q â‰¤ r, (1-q)r if q &gt; r.</p><p>Example 2. (Quadratic loss estimation) Suppose A = co (â„¦) âŠ‚ R and u Q (a, Ï‰) = -(a -Ï‰) 2</p><p>where co denotes convex hull. The optimal action given belief q is E q [Ï‰], the value of information is <ref type="foot" target="#foot_12">foot_12</ref> v Q (p, q) = (Ep [Ï‰] âˆ’ Eq [Ï‰])2 , and the cost of uncertainty is <ref type="foot" target="#foot_13">foot_13</ref> C Q (q) = Varq [Ï‰].</p><p>Example 3. (Brier elicitation) Consider some arbitrary (finite) Î©, let A = âˆ† (Î©), and suppose uB (a, Ï‰) = âˆ’kaâˆ’Î´Ï‰ k2 , where kÂ·k denotes the Euclidean norm. In other words, the action is a report of a probability distribution, and the utility is the <ref type="bibr" target="#b5">Brier score (1950)</ref> of the accuracy of the report. The optimal action given belief q is to set a = q, the value of information is v B (p, q) = p -q 2 , and the cost of uncertainty is C B (q) = Ï‰ q Ï‰ (1 -q Ï‰ ). <ref type="bibr" target="#b14">Ely et al. (2015)</ref> refer to C B as residual variance.</p><p>Note that quadratic loss estimation coincides with Brier elicitation (subject to a scaling factor)</p><p>when the state space is binary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Measures of information and uncertainty</head><p>A measure of information d is a function that maps a pair of beliefs to a real number.<ref type="foot" target="#foot_14">foot_14</ref> We interpret</p><p>d (p, q) as the amount of information in a piece of news that moves a Bayesian's belief from prior q to posterior p.<ref type="foot" target="#foot_15">foot_15</ref> A measure of uncertainty H is a function that maps a belief to a real number.</p><p>We interpret H (q) as the amount of uncertainty faced by a decision-maker with belief q.</p><p>One natural measure of information is the Euclidean distance between the beliefs, i.e., d (p, q) = kp âˆ’ qk. Another candidate measure would be distance-squared, kp âˆ’ qk2 . Measures of information can also depend only on some some â€œsummary statisticâ€, e.g., if Î© âŠ‚ R, we might set d (p, q) = (E p [Ï‰] -E q [Ï‰]) 2 . Finally, note that a measure of information need not be symmetric, e.g., it might be Kullback-Leibler divergence, Ï‰ p Ï‰ log p Ï‰ q Ï‰ .</p><p>Commonly encountered measures of uncertainty include variance H (q) = Var q [Ï‰] (when â„¦ âŠ‚ R) and Shannon entropy H (q) =Ï‰ q Ï‰ log q Ï‰ .</p><p>We are interested in whether the aforementioned (and other) measures of information and uncertainty quantify attitudes toward information in some decision problem. Say a measure of information d is valid if there is a decision problem D such that d is a value of information for D, and say a measure of uncertainty H is valid if there is a decision problem D such that H is the cost of uncertainty for D.</p><p>We are also interested in whether a given measure of information and a measure of uncertainty are "consistent" with each other. We introduce two notions of consistency. Say that d and H are jointly valid if they arise from the same decision problem, i.e., there is a decision problem D such that d is a value of information for D and H is the cost of uncertainty for D. We say that d and H are coupled if for any prior q and any signal Ï€ s , we have E [d (q (s) , q)] = E [H (q) -H (q (s))]; in other words, the expected amount of information generated equals the expected reduction in uncertainty.<ref type="foot" target="#foot_16">foot_16</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Main results</head><p>In this section, we answer the two questions posed at the end of the previous section: (i) which measures of information and uncertainty are valid, and (ii) which measures of information and uncertainty are consistent with each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Valid measures of information</head><p>Consider the following potential properties of a measure of information.</p><p>(Null-information) d (q, q) = 0 âˆ€q.</p><p>(Positivity) d (p, q) â‰¥ 0 âˆ€ (p, q).</p><p>(Order-invariance) Given any prior and pair of signals, the expected sum of information generated by the two signals is independent of the order in which they are observed. Formally, for any q, Ï€Î± , and Ï€Î² , we have</p><formula xml:id="formula_2">ğ”¼[d(q(Î±),q) + d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[d(q(Î²),q) + d(q(Î±âˆ©Î²),q(Î²))]</formula>.<p>Null-information and Positivity impose ex post properties on the realized amount of information while Order-invariance imposes an ex ante property regarding the expected amount of information that will be generated.<ref type="foot" target="#foot_17">foot_17</ref></p><p>In our approach, a measure of information is a function of just the prior and the posterior. This means that it explicitly excludes news that does not affect the posterior. In other words, it does not ascribe value to news that is useful only insofar as it changes the interpretation of other signals <ref type="bibr" target="#b3">(BÃ¶rgers et al. 2013)</ref>. Accordingly, Null-information states that news that does not change beliefs does not generate information.</p><p>Positivity requires that the amount of information received is always weakly positive, even from the ex post perspective. This puts it in contrast with the approach common in information theoryand often used in the economics literature on rational inattention (e.g., <ref type="bibr" target="#b27">Sims 2003)</ref> -that measures information as the expected reduction in entropy. Because a particular piece of news can increase entropy, ex post information measured by reduction in entropy can be negative.</p><p>Order-invariance concerns sequences of signals. It echoes a crucial feature of Bayesian updating, namely that the order in which information is observed cannot affect its overall content. That is, observing Ï€ Î± followed by Ï€ Î² leads to the same final distribution of posteriors as observing Ï€ Î² followed by Ï€ Î± . Order-invariance requires that these two sequences therefore must generate the same expected sum of ex post information. While Order-invariance is stated in terms of pairs of signals, in combination with Null-information, it guarantees that sequences of any number of signals that lead to the same final distribution of posteriors necessarily generate the same expected sum of information.</p><p>Theorem 1. A measure of information is valid if and only if it satisfies Null-information, Positivity, and Order-invariance.</p><p>Proofs are postponed until Section 3.6. A property closely related to Order-invariance would be that the expected sum of information generated by observing one signal and then the other is the same as the expected amount of information generated by observing the two signals at once. Formally, say that d satisfies Combination-invariance if for any q, Ï€ Î± , and Ï€ Î² , we have</p><formula xml:id="formula_3">ğ”¼[d(q(Î±),q) + d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[d(q(Î±âˆ©Î²),q)]</formula>.<p>It turns out that Combination-invariance is equivalent to Null-information and Order-invariance (cf: Appendix A). Therefore, Theorem 1 can alternatively be stated in terms of Positivity and Combination-invariance.</p><p>Theorem 1 not only identifies the precise set of properties that a measure of information compatible with a decision-theoretic foundation must satisfy, it also provides an easy way to test whether a given measure is valid or not. It is of course straightforward to check Null-information and Positivity, and in Section 3.4 we establish two simple tests for Order-invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Valid measures of uncertainty</head><p>It is easy to see that for any decision problem, the cost of uncertainty is concave and equal to zero when the decision-maker knows the state. It turns out that these two properties are not only necessary but sufficient for validity. Formally, consider the following two properties:</p><p>(Null-uncertainty) H (Î´ Ï‰ ) = 0 for all Ï‰, (Concavity) H is concave.</p><p>Theorem 2. A measure of uncertainty is valid if and only if it satisfies Null-uncertainty and Concavity.</p><p>Note that Null-uncertainty and Concavity jointly imply that H is positive everywhere. Moreover, the concavity of H implies that observing any signal necessarily reduces expected uncertainty, i.e., for any q and Ï€s , E [H (q (s))] â‰¤ H (q).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Consistency of measures of information and uncertainty</head><p>In Section 2.3, we introduced two distinct notions of consistency, joint validity and coupling. Here we show that (given valid measures of information and uncertainty), these two notions of consistency coincide. Moreover, there are specific functional forms that relate the two measures.</p><p>Recall that a supergradient of a concave function H at belief q is a vector âˆ‡H (q) such that for any belief p we have H (q) + âˆ‡H (q) Â· (p âˆ’ q) â‰¥ H (p). For any concave function, âˆ‡H (q) exists for all q. <ref type="foot" target="#foot_18">foot_18</ref> When H is smooth at q, âˆ‡H (q) is unique and equal to H 0 (q). A Bregman divergence of a concave function H is a function from (p, q) to the real numbers equal to H (q) âˆ’ H (p) + âˆ‡H (q) Â· (p âˆ’ q) for some supergradient âˆ‡H (q) of H at q <ref type="bibr" target="#b4">(Bregman 1967)</ref>.</p><p>Theorem 3. Given a valid measure of information d and a valid measure of uncertainty H, the following are equivalent: (1) d and H are jointly valid, (2) d and H are coupled, (3) d is a Bregman divergence of H, (4) H (q) = Ï‰ q Ï‰ d (Î´Ï‰ , q). Moreover, as Propositions 3 and 4 below clarify, given any valid H, d is jointly valid with H if and only if it is the Bregman divergence <ref type="foot" target="#foot_19">foot_19</ref> of H, and given any valid d, H is jointly valid with d if and only if H (q) = Ï‰ q Ï‰ d (Î´Ï‰ , q).</p><p>Note that the relationship between d and H expressed by part (4) of Theorem 3 has a simple interpretation: uncertainty is the expected amount of information generated by observing a fully revealing signal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Checking validity</head><p>Theorem 2 provides an easy way to confirm whether a given measure of uncertainty is valid. Applying Theorem 1 to check whether a given measure of information is valid may not seem as straightforward because it requires checking Order-invariance, which is not a self-evident property. Fortunately, however, there are two ways around this issue.</p><p>First, if a measure of information is smooth, it is possible to confirm whether it satisfies Order-invariance simply by inspecting its derivatives:</p><p>Proposition 1. Suppose a measure of information d is twice-differentiable in p for all q and 2 d(p,q) satisfies Null-information. Then, d satisfies Order-invariance if and only if âˆ‚ âˆ‚p is independent of q.</p><p>Second, the functional forms from Theorem 3 provide an easy way to check whether a measure of information (smooth or not) satisfies Order-invariance.</p><p>Proposition 2. Suppose a measure of information d satisfies Null-information and Positivity.</p><p>Then, d satisfies Order-invariance if and only if d is a Bregman divergence of âˆ‘qÏ‰d(Î´Ï‰,q).</p><p>Proposition 2 is easily applied since confirming whether</p><formula xml:id="formula_4">d(p,q) = âˆ‘qÏ‰d(Î´Ï‰,q) - âˆ‘pÏ‰d(Î´Ï‰,p) + âˆ‡(âˆ‘qÏ‰d(Î´Ï‰,q))Â·(p-q)</formula><p>is a straightforward computation for any given d. Moreover, since a Bregman divergence cannot be a metric,<ref type="foot" target="#foot_20">foot_20</ref> Proposition 2 also implies that any metric on the space of beliefs violates Orderinvariance.</p><p>Corollary 1. If a measure of information d is a metric on âˆ† (â„¦), it does not satisfy Orderinvariance.</p><p>Proofs of these results are in the Appendix. Corollary 1 further implies that no metric can be coupled with any measure of uncertainty, since (as shown below in Lemma 3) coupled measures necessarily satisfy Order-invariance.<ref type="foot" target="#foot_21">foot_21</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Discussion</head><p>Consider again the examples of decision problems from Section 2. Recall that the value of information for a simple decision problem with cutoff r is vÊ³(p,q) = |p-r| if r âˆˆ (min{p,q}, max{p,q}), |p-r|/2 if r=q, 0 otherwise and the cost of uncertainty is CÊ³(q) = q(1-r) if q â‰¤ r, (1-q)r if q &gt; r. For quadratic loss estimation, the value of information is v Q (p, q) = (E p [Ï‰] -E q [Ï‰]) 2 , and the cost of uncertainty is C Q (q) = Var q [Ï‰]. vá´®(p,q) = â€–p-qâ€–Â² and Cá´®(q) = âˆ‘Ï‰ qÏ‰(1-qÏ‰).</p><p>Theorem 1 thus tells us that v r , v Q , and v B all satisfy Null-information, Positivity, and Orderinvariance,<ref type="foot" target="#foot_22">foot_22</ref> while Theorem 2 confirms that C r , C Q , and C B satisfy Null-uncertainty and Concavity. Moreover, Theorem 3 tells us that each of these pairs of measures is coupled. If we want our measure of uncertainty to be "consistent" with our measure of information (in the sense that any signal generates information to the same extent that it reduces uncertainty), then we can measure uncertainty with C r and information with v r , or we can measure uncertainty with C Q and information with v Q , etc., but we cannot "mix and match".</p><p>In fact, our results imply that every concave function (equal to zero at degenerate beliefs) is a valid measure of uncertainty and is consistent with some measure of information -namely its Bregman divergence. Take entropy -perhaps the most widely used measure of uncertainty -for example. Our results tell us that entropy H (q) =Ï‰ q Ï‰ log q Ï‰ is coupled with its Bregman divergence, which, as shown by <ref type="bibr" target="#b4">Bregman (1967)</ref>, is Kullback-Leibler divergence, d(p,q) = âˆ‘Ï‰ pÏ‰ log(pÏ‰/qÏ‰).</p><p>For every signal, the expected reduction in entropy equals the expected Kullback-Leibler divergence. Such coupling (with a suitable measure of information) is not a special feature of entropy, but rather holds for any normalized concave function.<ref type="foot" target="#foot_23">foot_23</ref> Indeed, the fact that for any signal, the expected reduction in residual variance equals the expected quadratic distance between the prior and the posterior plays a central role in the derivation of suspense-optimal entertainment policies in <ref type="bibr" target="#b14">Ely (2015)</ref>. <ref type="bibr" target="#b0">Augenblick and Rabin (2018)</ref> also emphasize this result (cf: their Proposition 1) and use it as a cornerstone for an empirical test of rationality of belief updating. They also introduce a class of measures of uncertainty and coupled measures of information <ref type="foot" target="#foot_24">foot_24</ref> that encompass variance (coupled with quadratic distance) and entropy (coupled with Kullback-Leibler divergence). <ref type="foot" target="#foot_25">foot_25</ref></p><p>Moreover, Theorem 3 tells us that we can "microfound" any (normalized, concave) measure of uncertainty -and its coupled measure of information -as arising from some decision problem. In fact, the constructive proof of Proposition 6 provides an explicit algorithm for finding the underlying decision problem. Given the H and the d, if we set A = âˆ† (â„¦) and u (a, Ï‰) = -d (Î´ Ï‰ , a), we obtain</p><p>H as the cost of uncertainty and d as the value of information. <ref type="foot" target="#foot_26">foot_26</ref> These decision problems can be interpreted as follows: the action is a report of a probability distribution of an unknown variable, and utility is maximized by reporting one's true belief. This interpretation elucidates the connection between our results and the literature on scoring rules. The relationship between proper scoring rules, decision problems, and Bregman divergences has previously been explored by <ref type="bibr" target="#b17">Gneiting and Raftery (2007)</ref>.</p><p>Consider entropy. If we set A = âˆ† (â„¦) and u KL (a, Ï‰) = -log a Ï‰ (letting u (a, Ï‰) = -âˆ if a Ï‰ = 0), we get entropy as the cost of uncertainty (C KL (q) =Ï‰ q Ï‰ log q Ï‰ ) and Kullback-Leibler divergence as the value of information (v KL (p, q) = p Ï‰ log p Ï‰ q Ï‰ ). <ref type="foot" target="#foot_27">foot_27</ref> This utility function corresponds to the familiar logarithmic scoring rule <ref type="bibr" target="#b18">(Good 1952)</ref>. This example also illustrates why we needed to extend the potential range of the utility function to negative infinity in our definition of decision problems (cf: footnote <ref type="foot" target="#foot_7">8</ref>). Some measures of uncertainty, such as entropy, have the property that the marginal reduction of uncertainty goes to infinity as the belief approaches certainty; the extended range allows us to microfound such measures. There is no decision problem with a finite-valued utility function that has entropy as its cost of uncertainty.</p><p>That said, a decision problem that has some particular d and H as its value of information and cost of uncertainty is not unique.<ref type="foot" target="#foot_28">foot_28</ref> In information theory, entropy and Kullback-Leibler divergence are often presented as arising from a decision problem that is quite different from A = âˆ† (â„¦) and u (a, Ï‰) = -log a Ï‰ . If a decision-maker needs to choose a code, i.e., a map from Ï‰ to a string in some alphabet, aiming to minimize the expected length of the string, entropy arises as the cost of uncertainty and Kullback-Leibler divergence arises as the value of information <ref type="bibr" target="#b11">(Cover &amp; Thomas 2012)</ref>. Our results can thus be seen as providing an alternative -and arguably simpler -decisiontheoretic microfoundation for these widely used measures. <ref type="foot" target="#foot_29">foot_29</ref> In the next section, we provide yet another foundation for entropy and Kullback-Leibler divergence in terms of collections of simple decision problems. In fact, we show that (when the state space in binary), every valid measure of information or uncertainty can be expressed as arising from some collection of simple decision problems.</p><p>Our results are also useful insofar as they reveal that certain seemingly sensible measures of information are not valid, i.e., cannot be a microfoundation in our decision-theoretic terms. For example, Euclidean distance between the prior and the posterior is not a valid measure of information. While this measure satisfies Null-information and Positivity, it is easy to see that it does not satisfy Order-invariance. Under this measure, any partially informative signal followed by a fully informative signal yields a higher expected sum of information than a fully informative signal does on its own. In fact, Corollary 1 tells us that every metric violates Order-invariance. Hence, Theorem 1 implies that there does not exist a decision problem whose value of information is a metric on beliefs.</p><p>Finally, Theorem 3 highlights a geometric relationship between uncertainty and information through the Bregman divergence characterization. Figure <ref type="figure" target="#fig_0">1</ref> depicts the aforementioned measures of uncertainty, while Figure <ref type="figure" target="#fig_1">2</ref> illustrates the connection between an arbitrary valid measure of uncertainty and its coupled measure of information.</p></div>
			<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Proof of Theorems 1-3</head><p>We begin with a Lemma that will be referenced in a number of proofs.</p><p>Lemma 1. For any prior q, signals Ï€ Î± and Ï€ b , and d and H that are coupled, E [d (q (Î± âˆ© Î²) , q (Î±))] = E [H (q (Î±)) âˆ’ H (q (Î± âˆ© Î²))].</p><p>Proof of Lemma 1. By the law of iterated expectations:</p><formula xml:id="formula_5">ğ”¼[d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[ğ”¼[d(q(Î±âˆ©Î²),q(Î±))|Î±]] = ğ”¼[ğ”¼[H(q(Î±)) - H(q(Î±âˆ©Î²))|Î±]] = ğ”¼[H(q(Î±)) - H(q(Î±âˆ©Î²))].</formula><p>Next we present two Propositions that relate coupling of d and H with the properties of d and H.</p><p>Proposition 3. Consider a measure of information d that satisfies Null-information, Positivity, and Order-invariance. There exists a unique measure of uncertainty that satisfies Null-uncertainty and Concavity, and is coupled with d, namely H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q).</p><p>To establish Proposition 3, we first establish that Null-information and Order-invariance alone suffice to establish that H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q) is coupled with d and satisfies Null-uncertainty. We then show that the addition of Positivity of d implies Concavity of H. Finally, we establish that this is the only function that is coupled with d and satisfies Null-uncertainty.</p><p>Lemma 2. Given a measure of information d that satisfies Null-information and Order-invariance, let H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q). Then, H is coupled with d and satisfies Null-uncertainty.</p><p>Proof of Lemma 2. Given a measure of information d that satisfies Null-information, and Order-invariance, let H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q). Consider some q and some signal Ï€Î±. To show that H is coupled with d, we need to show ğ”¼[d(q(Î±),q)] = ğ”¼[H(q) - H(q(Î±))]. Let Ï€Î² be a fully informative signal. First, consider observing Ï€Î² followed by Ï€Î±. Since Ï€Î² is fully informative, ğ”¼[d(q(Î²),q)] = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q) = H(q). Furthermore, Ï€Î± cannot generate any additional information so Î±âˆ©Î² = Î², and hence by Null-information of d, we have that ğ”¼[d(q(Î±âˆ©Î²),q(Î²))] = 0. Thus, the expected sum of information generated by observing Ï€Î² followed by Ï€Î± (i.e., ğ”¼[d(q(Î²),q) + d(q(Î±âˆ©Î²),q(Î²))]) equals H(q). Now consider observing Ï€Î± followed by Ï€Î². This generates expected sum of information equal to ğ”¼[d(q(Î±),q) + d(q(Î±âˆ©Î²),q(Î±))]. Moreover, ğ”¼[d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[âˆ‘Ï‰ qÏ‰(Î±)d(Î´Ï‰,q(Î±))] = ğ”¼[H(q(Î±))]. Hence, by Order-invariance, we have H(q) = ğ”¼[d(q(Î±),q) + d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[d(q(Î±),q) + H(q(Î±))], i.e., ğ”¼[d(q(Î±),q)] = ğ”¼[H(q) - H(q(Î±))]. Hence, H is coupled with d. Finally, Null-information and H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q) jointly imply Null-uncertainty.</p><p>We now turn to the proof of Proposition 3.</p><p>Proof of proposition 3. Consider a measure of information d that satisfies Null-information, Positivity, and Order-invariance. Let H(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q). To show H is concave, we need to establish that for any q and any Ï€s, we have ğ”¼[H(q) - H(q(s))] â‰¥ 0. By Lemma 2, we know that ğ”¼[H(q) - H(q(s))] = ğ”¼[d(q(s),q)]. By Positivity, d(q(s),q) â‰¥ 0 for any s. Hence, ğ”¼[H(q) - H(q(s))] â‰¥ 0. It remains to show that H(q) is the unique function that is coupled with d and satisfies Null-uncertainty. Consider a fully informative signal Ï€s and some Ä¤ that is coupled with d and satisfies Null-uncertainty. We have that Ä¤(q) - ğ”¼[Ä¤(q(s))] = ğ”¼[d(q(s),q)] = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q). Null-uncertainty implies that ğ”¼[Ä¤(q(s))] = 0. Hence, Ä¤(q) = âˆ‘Ï‰ qÏ‰d(Î´Ï‰,q).</p><p>Proposition 4. Given a measure of uncertainty H that satisfies Null-uncertainty and Concavity, d is a measure of information that satisfies Null-information, Positivity, and Order-invariance, and is coupled with H if and only if d is a Bregman divergence of H.</p><p>We begin the proof with two Lemmas of independent interest:</p><p>Lemma 3. If a measure of information d is coupled with some measure of uncertainty H, d satisfies Order-invariance.</p><p>Proof of Lemma 3. Consider any d and H that are coupled. Given any q and pair of signals Ï€Î± and Ï€Î², applying Lemma 1,</p><formula xml:id="formula_6">ğ”¼[d(q(Î±),q) + d(q(Î±âˆ©Î²),q(Î±))] = ğ”¼[(H(q) - H(q(Î±))) + (H(q(Î±)) - H(q(Î±âˆ©Î²)))] = ğ”¼[H(q) - H(q(Î±âˆ©Î²))],</formula><p>and by the same argument ğ”¼[d(q(Î²),q) + d(q(Î±âˆ©Î²),q(Î²))] = ğ”¼[H(q) - H(q(Î±âˆ©Î²))]. Hence, d satisfies Order-invariance.</p><p><head>Lemma 4.</head> Given any measure of uncertainty H, a measure of information d is coupled with H if and only if d(p,q) = H(q) - H(p) + f(q)Â·(p-q) for some function f.</p><p>Proof of Lemma 4. Suppose some d and H are coupled. Fix any q. We know that for any signal Ï€s, ğ”¼[d(q(s),q) - H(q) + H(q(s))] = 0. Since this expression is constant across all signals, ğ”¼pâˆ¼Ï„[d(p,q) - H(q) + H(p)] is constant across all distributions of posteriors Ï„ s.t. ğ”¼pâˆ¼Ï„[p] = q <ref type="bibr" target="#b21">(Kamenica and Gentzkow 2011)</ref>. This in turn implies that d(p,q) - H(q) + H(p) is some affine function of p, f(q)p + g(q). Now, since ğ”¼pâˆ¼Ï„[f(q)Â·p + g(q)] = 0 for all Ï„ s.t. ğ”¼pâˆ¼Ï„[p] = q, it must be that g(q) = -f(q)q. Hence, d(p,q) - H(q) + H(p) = f(q)Â·(p-q).</p><p>We are now ready to prove Proposition 4.</p><p>Proof of Proposition 4. We first establish the "if" direction. Consider some H that satisfies Null-uncertainty and Concavity. Let d(p,q) = H(q) - H(p) + âˆ‡H(q)Â·(p-q) for some supergradient âˆ‡H(q). Note that for any q and any Ï€s, we have ğ”¼[âˆ‡H(q)Â·(q(s)-q)] = 0 and thus ğ”¼[d(q(s),q)] = ğ”¼[H(q) - H(q(s))]. Since this holds for all signals, d is coupled with H. Next, by Lemma 3, d satisfies Order-invariance. It is obvious that d satisfies Null-information and since it is a Bregman divergence of a concave function, it satisfies Positivity. To establish the "only if" direction, consider any d that is coupled with H and satisfies Positivity. Lemma 4 shows that d(p,q) = H(q) - H(p) + f(q)Â·(p-q) for some function f. Positivity implies that H(q) - H(p) + f(q)Â·(p-q) â‰¥ 0 for all pairs (p,q), which means that f(q) is a supergradient of H(q).</p><p>We now turn to two Propositions that relate validity of d and H with the properties of d and H.</p><p>Proposition 5. Given a decision problem ğ’Ÿ, let vğ’Ÿ be a value of information for ğ’Ÿ and let Cğ’Ÿ be the cost of uncertainty for ğ’Ÿ. Then: 1. vğ’Ÿ satisfies Null-information, Positivity, and Order-invariance, 2. Cğ’Ÿ satisfies Null-uncertainty and Concavity, 3. vğ’Ÿ and Cğ’Ÿ are coupled.</p><p>Proof of Proposition 5. To establish (2), we note that ğ”¼q[maxa[u(a,Ï‰)]] is linear in q while maxa[ğ”¼q[u(a,Ï‰)]] is convex in q; thus Cğ’Ÿ is concave. It is immediate that Cğ’Ÿ satisfies Null-uncertainty. To establish (3), consider some q and some signal Ï€s. Then,</p><formula xml:id="formula_7"> ğ”¼[Cğ’Ÿ(q) - Cğ’Ÿ(q(s))] = ğ”¼[ğ”¼q[maxa[u(a,Ï‰)]] - maxa[ğ”¼q[u(a,Ï‰)]] - ğ”¼q(s)[maxa[u(a,Ï‰)]] + maxa[ğ”¼q(s)[u(a,Ï‰)]]] = ğ”¼[maxa[ğ”¼q(s)[u(a,Ï‰)]] - maxa[ğ”¼q[u(a,Ï‰)]]]</formula><p>since ğ”¼[ğ”¼q[maxa[u(a,Ï‰)]] - ğ”¼q(s)[maxa[u(a,Ï‰)]]] = 0 by the law of iterated expectations. Moreover,</p><formula xml:id="formula_8">ğ”¼[vğ’Ÿ(q(s),q)] = ğ”¼[maxa[ğ”¼q(s)[u(a,Ï‰)]] - ğ”¼q(s)[u(a*(q),Ï‰)]] = ğ”¼[maxa[ğ”¼q(s)[u(a,Ï‰)]] - maxa[ğ”¼q[u(a,Ï‰)]]]</formula><p>for any optimal action a*(q) since for any such action ğ”¼[ğ”¼q(s)[u(a*(q),Ï‰)]] = ğ”¼q[u(a*(q),Ï‰)] = maxa[ğ”¼q[u(a,Ï‰)]]. Thus, ğ”¼[Cğ’Ÿ(q) - Cğ’Ÿ(q(s))] = ğ”¼[vğ’Ÿ(q(s),q)]. Finally, to establish (1), note that Null-information and Positivity are immediate while Order-invariance follows from (3) by Lemma 3.</p><p>Proposition 6. Suppose a measure of information d satisfies Null-information, Positivity, and Order-invariance; a measure of uncertainty H satisfies Null-uncertainty and Concavity; and d and H are coupled. There exists a decision problem ğ’Ÿ such that (i) d is a value of information for ğ’Ÿ and (ii) H is the cost of uncertainty for ğ’Ÿ.</p><p>Proof of Proposition 6. Suppose a measure of information d satisfies Null-information, Positivity, and Order-invariance; a measure of uncertainty H satisfies Null-uncertainty and Concavity; and d and H are coupled. Let ğ’Ÿ = (A,u) with A = Î”(Î©) and u(a,Ï‰) = -d(Î´Ï‰,a) if aÏ‰ > 0, -âˆ otherwise. <ref type="foot" target="#foot_30">foot_30</ref> First, we note that for any p and q such that qÏ‰ > 0 â‡’ pÏ‰ > 0 we have:</p><formula xml:id="formula_9">ğ”¼q[u(q,Ï‰) - u(p,Ï‰)] = ğ”¼q[-d(Î´Ï‰,q) + d(Î´Ï‰,p)] = ğ”¼q[-H(q) + H(Î´Ï‰) - âˆ‡H(q)(Î´Ï‰-q) + H(p) - H(Î´Ï‰) + âˆ‡H(p)(Î´Ï‰-p)] = H(p) - H(q) + âˆ‡H(p)(q-p) = d(q,p),</formula><p>where the third equality holds because ğ”¼q[Î´Ï‰] = q. Any optimal action clearly satisfies qÏ‰ > 0 â‡’ (a*(q))Ï‰ > 0, so for any action p that might be optimal, we have</p><formula xml:id="formula_10">ğ”¼q[u(q,Ï‰) - u(p,Ï‰)] = d(q,p) â‰¥ 0.<label>(1)</label></formula><p>Hence, at any belief q, action q yields as high a payoff as any alternative action p. The value of information for ğ’Ÿ, moving from prior q to posterior p is ğ”¼p[u(a*(p),Ï‰)] - ğ”¼p[u(a*(q),Ï‰)] = ğ”¼p[u(p,Ï‰) - u(q,Ï‰)]. By the equality in Equation (1), ğ”¼p[u(p,Ï‰) - u(q,Ï‰)] = d(p,q). Hence, d is a value of information for ğ’Ÿ. By Proposition 5, d thus must be coupled with the cost of uncertainty for ğ’Ÿ which satisfies Null-uncertainty and Concavity. By Proposition 3, H is the unique measure of uncertainty that satisfies Null-uncertainty and Concavity and is coupled with d. Hence, H must be the cost of uncertainty for ğ’Ÿ.</p><p>We are now ready to prove the main Theorems.</p><p>Proof of Theorem 1. Suppose some measure of information d is valid. By Proposition 5, it satisfies Null-information, Positivity, and Order-invariance. Suppose d satisfies Null-information, Positivity, and Order-invariance. By Proposition 3, it is coupled with some measure of uncertainty that satisfies Null-uncertainty and Concavity. Hence, by Proposition 6, it is valid.</p><p>Proof of Theorem 2. Suppose some measure of uncertainty H is valid. By Proposition 5, it satisfies Null-uncertainty and Concavity. Suppose H satisfies Null-uncertainty and Concavity. By Proposition 4, it is coupled with some measure of information that satisfies Null-information, Positivity, and Order-invariance. Hence, by Proposition 6, it is valid.</p><p>Proof of Theorem 3. (1) implies (2) by Proposition 5. (2) implies (1) by Theorems 1 and 2 and Proposition 6. (2) is equivalent to (3) by Theorems 1 and 2 and Proposition 4. (2) is equivalent to (4) by Theorems 1 and 2 and Proposition 3.</p></div>
			<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Collections of simple decision problems</head><p>As we noted in the previous section, two decision problems can be equivalent in the sense that they have the same cost of uncertainty. Similarly, some collection of decision problems can induce the same attitude toward information and uncertainty as some particular decision problem ğ’Ÿ. In this section, we show that, when the state space is binary, every decision problem corresponds to some collection of simple decision problems. Formally, a simple decision environment Î¼ is a measure on [0,1] with the interpretation that the decision-maker faces a collection of simple decision problems with the measure indicating their prevalence. The <term>cost of uncertainty of q given Î¼</term> - denoted KÎ¼(q) - is the reduction in the decision-maker's payoff, aggregated across the decision problems in Î¼, due to her ignorance of the state of the world, i.e.,</p><formula xml:id="formula_11">KÎ¼(q) = âˆ« [ğ”¼q[maxa[uÊ³(a,Ï‰)]] - maxa[ğ”¼q[uÊ³(a,Ï‰)]]] dÎ¼(r)</formula><p>Given a binary state space, we say that a decision problem ğ’Ÿ is equivalent to a simple decision environment Î¼ if Cğ’Ÿ(q) = KÎ¼(q) for all q.<ref type="foot" target="#foot_31">foot_31</ref></p><p>Our main result in this section is that every decision problem is equivalent to some simple decision environment. This basically means that (when the state space is binary) we can think of the simple decision problems as "a basis" for all decision problems, at least as far as value of information is concerned. This result is closely related to the characterization of proper scoring rules in <ref type="bibr" target="#b26">Schervish (1989)</ref>.</p><p>roposition 7. Suppose the state space is binary. Every decision problem is equivalent to some simple decision environment.</p><p>Formal proof is in the Appendix, but to get some intuition for this result, first consider a simple decision environment that puts measure 1 on some simple decision problem r. Its cost of uncertainty, as noted above, is CÊ³(q) = q(1-r) if q â‰¤ r, (1-q)r if q > r, i.e., a piecewise linear function with slope 1-r for q &lt; r and slope -r for q &gt; r; in other words, the decrease in slope at r is 1. Next, consider an environment that puts measure Î· on some simple decision problem r. Its cost of uncertainty is just Î·CÊ³(q) with the decrease in slope at r of Î·. Now, consider an environment Î¼ = ((Î·1,r1),...,(Î·k,rk)) that puts measure Î·i on simple decision problem ri for i âˆˆ {1,...,k}. Its cost of uncertainty KÎ¼(q) is âˆ‘i Î·iCÊ³â±(q), which is a piecewise linear function whose slope decreases by Î·i at each ri.</p><p>Hence, given any decision problem ğ’Ÿ with a finite action space A - and therefore a piecewise linear cost of uncertainty Cğ’Ÿ(q) - we can find an equivalent simple decision environment by putting a measure Î·i = limqâ†’riâ» Cğ’Ÿ'(q) - limqâ†’riâº Cğ’Ÿ'(q) (i.e., the decrease in slope) at each kink ri of Cğ’Ÿ(q).</p><p>For example, consider A = {x,m,y} and Î© = {X,Y}, where u(a,Ï‰) is indicated by the matrix: X Y x 1 0 m 1/3 3/4 y 0 1.</p><p>Under these preferences, x is optimal when the probability of Y is q â‰¤ 8/17, m is optimal for q âˆˆ [8/17,4/7], and y is optimal when q â‰¥ 4/7. Then, Cğ’Ÿ(q) is piecewise linear with kinks at r1 = 8/17 and r2 = 4/7 and slope decreases of 17/12 at r1 and 7/12 at r2. Therefore, this problem is equivalent to a simple decision environment that puts measure Î·1 = 17/12 on r1 = 8/17 and Î·2 = 7/12 on r2 = 4/7.</p><p>The logic above can be extended to decision problems with a continuous action space and smooth cost of uncertainty by setting the density of the simple decision environment equal to the infinitesimal decrease in slope of Cğ’Ÿ(q), i.e., -Cğ’Ÿ''(q). <ref type="foot" target="#foot_32">foot_32</ref> For example, consider the decision problem A = [0,1] and Î© = {X,Y} with u(a,Ï‰) = -aÂ²/4 if Ï‰=X, -(1-a)Â²/4 if Ï‰=Y whose cost of uncertainty Cğ’Ÿ(q) = q(1-q)/2 is proportional to residual variance. Since -Cğ’Ÿ''(q) = 1 for all q, this decision problem is equivalent to a uniform measure over simple decision problems. In other words, a decision-maker who is equally likely to face any simple decision problem has value of information and cost of uncertainty proportional to quadratic variation and residual variance, respectively.</p><p>Similarly, suppose the decision-maker faces the decision problem whose cost of uncertainty is entropy, i.e., A = [0,1] and Î© = {X,Y} with u(a,Ï‰) = -log(1-a) if Ï‰=X, -log(a) if Ï‰=Y. Since entropy is given by -q log q - (1-q) log(1-q), its second derivative is -1/(q(1-q)). Thus, a decision-maker has entropy-like attitude toward information and uncertainty when there is a high prevalence of simple decision problems with very low and very high cutoffs relative to those with cutoffs near 1/2. In fact, while the entropy-equivalent measure on any interval (z,Å¾) âŠ‚ (0,1) is finite, it diverges to infinity as z approaches 0 or Å¾ approaches 1. This is the primary reason why we needed to define simple decision environments as general measures (rather than probability distributions). The formulation in terms of measures allows us to accommodate costs of uncertainty - such as entropy - that have infinite slopes at the boundary. <ref type="foot" target="#foot_33">foot_33</ref></p><p>The environments that yield residual variance and entropy as costs of uncertainty can be seen as two elements of a parametric family of measures. Consider measures with density equal to q Î³ (1 âˆ’ q)Î³ for Î³ &gt; âˆ’2. When Î³ = 0, we have a uniform density and thus the cost of uncertainty is residual variance. When Î³ = âˆ’1, we get the density that yields entropy. For any Î³ > âˆ’1, the density integrates to a finite amount and thus can be scaled to a probability distribution (a symmetric Beta). For Î³ â‰¤ âˆ’1, the measure is not finite. Thus, entropy can be seen as the â€œborder caseâ€ between measures of uncertainty that are proportionally equivalent to probability distributions and those that are only equivalent to infinite measures. <ref type="foot" target="#foot_34">foot_34</ref></p><p>Proposition 7 also provides insight into the tests of rationality proposed by <ref type="bibr" target="#b0">Augenblick and Rabin (2018)</ref>. They emphasize that if a sequence of beliefs was formed through Bayes' rule, the expected sum of belief movements as measured by quadratic variation must equal residual variance of the initial belief, though as we mentioned in footnote 26, they discuss a broader (but non-comprehensive) class of tests. Our results imply that the set of all tests of Bayesian rationality that confirm expected reduction in uncertainty equals expected belief movement is spanned by picking <term>any</term> pair of functions H and f and then measuring uncertainty by H and belief movement by H(q) - H(p) + f(q)(p-q). Moreover, if one wishes to guarantee that belief movements are non-negative, H must be concave and f must be a supergradient of H.</p><p>That said, at least for the case of binary states, there is one sense in which <ref type="bibr" target="#b0">Augenblick and Rabin's (2018)</ref> choice to focus on quadratic variation is the most natural. Proposition 7 establishes that every test that defines belief movement as non-negative - and thus uses a valid measure of information as its measure of belief movement - implicitly puts a certain "weight" on movements that cross specific beliefs. For example, suppose we use vÊ³ with r=0.5 as the measure of belief movement. If a sequence of beliefs (q0,...,qT) was formed through Bayes' rule and qT is degenerate, it must be the case that âˆ‘t=1áµ€ vâ°Â·âµ(qt,qt-1) in expectation equals Câ°Â·âµ(q0). This test only "counts" movements that cross the belief r=0.5, ignoring all others. If we were to use Kullback-Leibler divergence as the measure of belief movement, we would implicitly be putting weight -1/(r(1-r)) on movements across r. Quadratic variation, the test used by <ref type="bibr" target="#b1">Augenblick and Rabin (2018)</ref>, implicitly assumes uniform weights across all movements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Buying information</head><p>In this section, we establish a relationship between valid measures of information and intertemporal incentive-compatibility constraints faced by a seller of information. Consider the following model of a buyer who compensates a seller for the information that the seller reveals.</p><p>The prior is q. There are two periods t âˆˆ {1, 2} and two available signals Ï€ Î± * (which arrives in period 1) and Ï€ Î² * (which arrives in period 2). The seller will eventually reveal all of the information from these signals, but may delay doing so. There are two types of delay to consider.</p><p>First, the seller can delay the arrival of information from the ex ante perspective. He can choose choose to get a (Blackwell) less informative signal in the first period and "transfer" the foregone information to the second period signal.</p><p>Second, he can delay the revelation of information in the interim stage. Following the realization Î± of Ï€ Î± , he can either reveal Î± or reveal no information. If he chooses to reveal Î± in period 1, in period 2 he will reveal simply the realization Î² of Ï€ Î² . If he chooses to reveal nothing in period 1, in period 2 he must reveal both Î± and Î². In other words, he can "hide" what he learned in period 1 and only reveal it in period 2 along with the new information that arrived in period 2.</p><p>The seller is paid for the information he reveals. Before any information is revealed, the prior is</p><p>q. The payment to the seller in period 1 is t (p 1 , q), and in period 2, it is t (p 2 , p 1 ) for some payment function t with p 1 and p 2 determined as follows. At period 1, if the seller revealed Î±, the posterior is p 1 = q (Î±) and if the seller revealed no information, we set p 1 = q.<ref type="foot" target="#foot_35">foot_35</ref> In either case, in period 2, the posterior is p 2 = q (Î± âˆ© b). The seller's objective is to maximize the expected sum of transfers.</p><p>We make two assumptions about t, namely that t (q, q) = 0 and t (p, q) â‰¥ 0 for every p and q.</p><p>We are interested in how the structure of t interacts with the seller's incentives to delay information</p><p>revelation. We say that t is ex ante incentive compatible if for any prior q and any pair of signals Ï€ Î± * and Ï€ Î² * , the seller weakly prefers to set Ï€ Î± = Ï€ Î± * (and thus Ï€ Î² = Ï€ Î² * ). We say that t is interim incentive compatible if for any prior q and any pair of signals Ï€ Î± and Ï€ Î² , the seller weakly prefers to reveal every signal realization Î± in period 1. If t is both ex ante and interim incentive compatible, we simply say it is incentive compatible.<ref type="foot" target="#foot_36">foot_36</ref></p><p>At first glance, it might seem that interim incentive compatibility is more difficult to satisfy than ex ante incentive compatibility since the seller can condition the decision of whether to delay on the first period's signal realization. This turns out not to be the case; in fact, ex ante incentive compatibility is the stronger condition. One example of a payment function that is interim but not ex ante incentive compatible is t (p, q) = kp âˆ’ qk. <ref type="foot" target="#foot_37">foot_37</ref> But, there is no payment function that is ex ante but not interim incentive compatible:</p><p>Lemma 5. Every payment function that is ex ante incentive compatible is interim incentive compatible.</p><p>We now turn to the question of which payment functions are (ex ante) incentive compatible.</p><p>We have seen that t (p, q) = p -q does not work. It turns out that this is closely tied to the fact that Euclidean distance is not a valid measure of information.</p><p>Theorem 4. A payment function is incentive compatible if and only if it is a valid measure of information.</p><p>Proof of the theorem is in the Appendix, but the basic approach is to show that if a payment function satisfies Order-invariance, then delaying any signal (at the ex ante or interim stage) has zero impact on the expected payment. Thus, the seller is always indifferent between revealing or delaying information. One may wish to find a payment function that induces a strict preference against delay, but since Theorem 4 is an if-and-only-if result, it tells us that any payment scheme that leads to a strict preference not to delay some information necessarily induces a strict preference to delay other information. Thus, making the seller indifferent about the delay is the only way to insure incentive compatibility.</p></div>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1:</head><label>1</label><figDesc>Figure 1: Measures of uncertainty</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2:</head><label>1</label><figDesc>Figure 1: Measures of uncertainty</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p><ref type="bibr" target="#b2">Blackwell (1951)</ref> provides an ordinal comparison of experiments without a reference to a specific prior or decision problem.<ref type="bibr" target="#b22">Lehmann (1988)</ref>,<ref type="bibr" target="#b25">Persico (2000)</ref>, and <ref type="bibr" target="#b7">Cabrales et al. (2013)</ref> consider ordinal comparisons on a restricted space of priors, problems, and/or experiments. One could also consider ordinal rankings of pieces of news from an ex post perspective, but we do not take that route in this paper.<ref type="bibr" target="#b13">De Lara and Gossner (2017)</ref> express the cardinal value of an experiment based on its influence on decisions.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>See, for example, <ref type="bibr" target="#b8">Caplin and Dean (2013)</ref>, <ref type="bibr" target="#b15">Gentzkow and Kamenica (2014)</ref>, <ref type="bibr" target="#b28">Steiner et al. (2017)</ref>, <ref type="bibr" target="#b29">Yoder (2016)</ref>, and <ref type="bibr" target="#b23">Mensch (2018)</ref>.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p><ref type="bibr" target="#b9">Caplin et al. (2017)</ref> refer to cost functions in this class as posterior separable.<ref type="bibr" target="#b20">HÃ©bert and Woodford (2017)</ref> and <ref type="bibr" target="#b24">Morris and Strack (2017)</ref> consider sequential sampling models that generate cost functions in this class. <ref type="bibr" target="#b23">Mensch (2018)</ref> provides an axiomatic foundation for posterior separable cost functions.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"> <p>Equivalent decision problems induce measures of information that are the same almost everywhere.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Note that, as long as the probability of s is strictly positive given q, Bayes' rule implies a unique q(s) which does not depend on the signal Ï€ from which s was realized. If probability of s is zero, we can set q(s) to an arbitrary belief.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>Since the set of all signals with the refinement order is a lattice, âˆ¨ indicates the join operator.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>In the expression ğ”¼[q(Î±)], the expectation is taken over the realization of Î± whose distribution depends on q.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>We explain below the benefit of including âˆ’âˆ in the range of the utility function. Given this extended range, we further assume that there exists some action a such that u (a, Ï‰) is finite for every Ï‰. We also assume the convention that âˆ’âˆ Ã— 0 = 0 so that taking an action that yields âˆ’âˆ in some state is not costly if that state has zero probability.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>We restrict the domain of v to be pairs (p,q) such that the support of p is a subset of the support of q, i.e., q Ï‰ = 0â‡’p Ï‰ = 0. We need not concern ourselves with movements of beliefs outside of this domain since they are not compatible with Bayesian updating.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>We also allow for a*(q) to be a distribution over optimal actions in which case u(a*(q),Ï‰) is interpreted to mean the expectation of u(a,Ï‰) given that distribution.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>Note that a given decision problem does not necessarily imply a unique vD (p, q) when the decision-maker is indifferent across multiple actions at belief q, but any two functions that are a value of information for the same decision problem will coincide for almost every q.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11"><p>These interpretations rely on the fact that no further information will arrive before the decision is made; the marginal value of this information would be different if outcomes of other signals were also to be observed prior to the decision.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12"><p>v^Q(p,q) = ğ”¼_p[-(ğ”¼_p[Ï‰] - Ï‰)^2 + (ğ”¼_q[Ï‰] - Ï‰)^2]
         = ğ”¼_p[-((ğ”¼_p[Ï‰])^2 - 2ğ”¼_p[Ï‰]Ï‰ + Ï‰^2) + ((ğ”¼_q[Ï‰])^2 - 2ğ”¼_q[Ï‰]Ï‰ + Ï‰^2)]
         = ğ”¼_p[-(ğ”¼_p[Ï‰])^2 + 2ğ”¼_p[Ï‰]Ï‰ + (ğ”¼_q[Ï‰])^2 - 2ğ”¼_q[Ï‰]Ï‰]
         = (-(ğ”¼_p[Ï‰])^2 + 2(ğ”¼_p[Ï‰])^2 + (ğ”¼_q[Ï‰])^2 - 2ğ”¼_q[Ï‰]ğ”¼_p[Ï‰])
         = (ğ”¼_p[Ï‰])^2 + (ğ”¼_q[Ï‰])^2 - 2ğ”¼_q[Ï‰]ğ”¼_p[Ï‰]
         = (ğ”¼_p[Ï‰] - ğ”¼_q[Ï‰])^2.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13"><p>C^Q(q) = ğ”¼_q[max_a[-(a - Ï‰)^2]] - max_a ğ”¼_q[-(a - Ï‰)^2]
       = 0 - max_a ğ”¼_q[-(a - Ï‰)^2]
       = -ğ”¼_q[-(ğ”¼_q[Ï‰] - Ï‰)^2]
       = Var_q[Ï‰].</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14"><p>As with value of information, we restrict the domain of d to be pairs (p,q) such that the support of p is a subset of the support of q.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15"><p>An alternative approach would be to take news as a primitive, define a piece of news n based on its likelihood in each state n(Ï‰), and introduce a measure of newsiness Î·(n,q) given a prior q. As long as two pieces of news n and n' with the same likelihood ratios yield Î·(n,q)=Î·(n',q), a measure of newsiness delivers a measure of information by setting d(p,q)=Î·(n,q) for p Ï‰ =n(Ï‰)q Ï‰/âˆ‘ Ï‰'n(Ï‰')q Ï‰'.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_16"><p>We will sometimes say "d is coupled with H" or "H is coupled with d" in place of "d and H are coupled."</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_17"><p>Note that requiring that d satisfy the ex post version of Order-invariance would be overly restrictive. Only d(p,q) identically equal to zero everywhere would satisfy Null-information, Positivity, and the ex post version of Order-invariance.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_18"><p>When q is interior, it is immediate that âˆ‡H(q) always exists. If q is at the boundary of Î”(Î©), we need to be somewhat careful. In particular, if qÏ‰=0, we set âˆ‡H(q)Ï‰=âˆ with âˆ‡H(q)Ï‰(p-q)Ï‰=0 if pÏ‰=qÏ‰; similarly, if qÏ‰=1, we set âˆ‡H(q)Ï‰=-âˆ with âˆ‡H(q)Ï‰(p-q)Ï‰=0 if pÏ‰=qÏ‰. These conditions guarantee that âˆ‡H(q) also exists at the boundary.</p>
</note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_19"><p><ref type="bibr" target="#b1">Banerjee et al. (2005)</ref> also use Bregman divergences as a foundation for measures of information, with applications to clustering problems in machine learning.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_20"><p>The only way that a Bregman divergence d can satisfy the triangle inequality on a triplet p, q, r when p is a convex combination of q and r is if d(p,q)=0. Therefore, a Bregman divergence cannot satisfy both the triangle inequality and d(p,q)=0â‡’p=q, and hence cannot be a metric (or a quasimetric*).</p><p>*Recall that a quasimetric is a function that satisfies all axioms for a metric with the possible exception of symmetry.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_21"><p><ref type="bibr" target="#b0">Augenblick and Rabin (2018)</ref> also note that there is no measure of uncertainty that can be coupled with Euclidean distance.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_22"><p>While the functional forms make Null-information and Positivity easy to see, simply inspecting these functions does not make it obvious that they satisfy Order-invariance. There is a simple direct proof (that considers arbitrary pairs of signals) of Order-invariance of v<sup>Q</sup> and v<sup>B</sup>, but directly establishing Order-invariance of v<sup>r</sup> is not as straightforward. One can also confirm v<sup>r</sup> satisfies Order-invariance via Proposition 2 (though as the proofs make clear, the arguments underlying Theorem 1 and Proposition 2 are closely related).</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_23"><p>By normalized, we simply mean a concave function that satisfies Null-uncertainty.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_24"><p>They term these "measures of movement."</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="26" xml:id="foot_25"><p>Assuming a binary state space {0,1}, <ref type="bibr" target="#b0">Augenblick and Rabin (2018)</ref> define a surprisal function as any decreasing Î³:[0,1]â†’â„<sub>+</sub> with Î³(1)=0 and let H(q)=qÎ³(q)+(1-q)Î³(1-q). They show each such H is coupled with d(p,q)=p(Î³(q)-Î³(p))+(1-p)(Î³(1-q)-Î³(1-p)). Measures of uncertainty that are generated this way are all symmetric around q=Â½, but they need not be concave nor equal to zero at degenerate beliefs. Likewise, the corresponding measures of information are not necessarily positive (even when H is concave). Thus, these measures of information and uncertainty are more restrictive than ours (due to symmetry), but are not always compatible with our decision-theoretic microfoundations (since they need not be valid). We discuss additional implications of our results for the questions explored by <ref type="bibr" target="#b0">Augenblick and Rabin (2018)</ref> in Section 4.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="27" xml:id="foot_26"><p>As we explain below, we in fact need to set u(a,Ï‰)={-d(Î´ Ï‰,a) if a Ï‰ &gt; 0 -âˆ otherwise}.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="28" xml:id="foot_27"><p>Note that -v KL (Î´Ï‰ , a) = Ï‰0 Î´Ï‰Ï‰ log aÏ‰Ï‰0 = âˆ’ log aÏ‰ .</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="29" xml:id="foot_28"><p>Our procedure utilizes decision problems from a specific class where A = âˆ† (Î©), but of course many measures of information and uncertainty arise from simpler decision problem with a finite action space.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30" xml:id="foot_29"><p>There are also various axiomatic approaches to deriving entropy and Kullback-Leibler divergence (cf: survey by <ref type="bibr" target="#b12">Csiszar 2008)</ref>.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="31" xml:id="foot_30"><p>While our proof employs payoffs of âˆ’âˆ, these are not needed if H is continuous and has finite derivatives.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="32" xml:id="foot_31"><p>We can also define value of information for a simple decision environment and note that if some function is a value of information both for some decision problem D and for some environment Î¼, then D and Î¼ are equivalent. That said, we define equivalence in terms of the cost of uncertainty, since that (unlike value of information) is unique for a given decision problem.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="33" xml:id="foot_32"><p>The formal proof handles mixtures of kinks and smooth decreases in CD(q).</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="34" xml:id="foot_33"><p>If Î¼ is equivalent to some D with cost of uncertainty C<sub>D</sub>(q), Î¼ must have measure of C'<sub>D</sub>(0)-C'<sub>D</sub>(1) on the unit interval.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="35" xml:id="foot_34"><p>When Î³â‰¤-2, the measure is not equivalent to any decision problem since it would imply an infinite cost of uncertainty for interior beliefs.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="36" xml:id="foot_35"><p>Note that if the decision not to reveal a conveys information about Ï‰, the equilibrium posterior p<sub>1</sub> would not equal q. However, we are interested in settings where the seller is paid for the explicit, verifiable information he provides and thus we rule out t being a function of updating based on implicit information.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="37" xml:id="foot_36"><p>As is typical, we only require that the seller weakly prefer not to delay. It is worthwhile to note that, not only is it not possible to construct a payment function that always gives a strict incentive not to delay, Theorem 4 below implies that any payment function that ever gives a strict incentive not to delay cannot be incentive compatible.</p></note>
<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="38" xml:id="foot_37"><p>Given any q and signal realizations Î± and Î², if q(Î±) is a convex combination of q and q(Î±âˆ©Î²), the payment under t(p,q)=â€–p-qâ€– is the same whether Î± had been revealed or not; otherwise, the payment is higher if Î± had been revealed. Hence, the payment function is interim incentive compatible. To see it is not ex ante incentive compatible, consider Ï€<sub>Î±*</sub> that is informative and Ï€<sub>Î²*</sub> that provides no information. Then, it is a profitable deviation to "split" the informational content of Ï€<sub>Î±*</sub> across the two periods.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>
	
	<biblStruct type="unpublished" xml:id="b0">
		<monogr>
			<author>
				<persName>
					<surname>Augenblick</surname>
					<forename>Ned</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Rabin</surname>
					<forename>Matthew</forename>
				</persName>
			</author>
			<title level="m">Belief Movement, Uncertainty Reduction, and Rational Updating</title>
			<imprint>
				<date when="2018">2018</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b1">
		<analytic>
			<author>
				<persName>
					<surname>Banerjee</surname>
					<forename>Arindam</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Merugu</surname>
					<forename>Srujana</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Dhillon</surname>
					<forename type="first">Inderjit</forename><forename type="middle">S</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Ghosh</surname>
					<forename>Joydeep</forename>
				</persName>
			</author>
			<title level="a">Clustering with Bregman Divergences</title>
		</analytic>
		<monogr>
			<title level="j">Journal of Machine Learning Research</title>
			<imprint>
				<date when="2005">2005</date>
				<biblScope unit="volume">6</biblScope>
				<biblScope unit="page" from="1705" to="1749"/>
			</imprint>
		</monogr>
	</biblStruct>

	<biblStruct type="proceeding" xml:id="b2">
		<analytic>
			<author>
				<persName>
					<surname>Blackwell</surname>
					<forename>David</forename>
				</persName>
			</author>
			<title level="a">Comparison of Experiments</title>
		</analytic>
		<monogr>
			<title level="m">Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability</title>
			<imprint>
				<publisher>University of California Press</publisher>
				<date when="1951">1951</date>
				<biblScope unit="page" from="93" to="102"/>
			</imprint>
		</monogr>
	</biblStruct>
	 
	<biblStruct type="article" xml:id="b3">
		<analytic>
			<author>
				<persName>
					<surname>BÃ¶rgers</surname>
					<forename>Tilman</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Hernando-Veciana</surname>
					<forename>Angel</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>KrÃ¤hmer</surname>
					<forename>Daniel</forename>
				</persName>
			</author>
			<title level="a">When Are Signals Complements or Substitutes?</title>
		</analytic>
		<monogr>
			<title level="j">Journal of Economic Theory</title>
			<imprint>
				<date when="2013">2013</date>
				<biblScope unit="volume">148</biblScope>
				<biblScope unit="page" from="165" to="95"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b4">
		<analytic>
			<author>
				<persName>
					<surname>Bregman</surname>
					<forename>Lev</forename>
				</persName>
			</author>
			<title level="a">The Relaxation Method of Finding the Common Points of Convex Sets and Its Application to the Solution of Problems in Convex Programming</title>
		</analytic>
		<monogr>
			<title level="j">USSR Computational Mathematics and Mathematical Physics</title>
			<imprint>
				<date when="1967">1967</date>
				<biblScope unit="volume">7</biblScope>
				<biblScope unit="page" from="200" to="217"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b5">
		<analytic>
			<author>
				<persName>
					<surname>Brier</surname>
					<forename type="first">Glenn</forename><forename type="middle">W</forename>
				</persName>
			</author>
			<title level="a">Verification of Forecasts Expressed in Terms of Probability</title>
		</analytic>
		<monogr>
			<title level="j">Monthly Weather Review</title>
			<imprint>
				<date when="1950">1950</date>
				<biblScope unit="volume">78</biblScope>
				<biblScope unit="page" from="1" to="3"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b6">
		<analytic>
			<author>
				<persName>
					<surname>Brunnermeier</surname>
					<forename type="first">Markus</forename><forename type="middle">K</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Parker</surname>
					<forename type="first">Jonathan</forename><forename type="middle">A</forename>
				</persName>
			</author>
			<title level="a">Optimal Expectations</title>
		</analytic>
		<monogr>
			<title level="j">American Economic Review</title>
			<imprint>
				<date when="2005">2005</date>
				<biblScope unit="volume">95</biblScope>
				<biblScope unit="page" from="1092" to="118"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b7">
		<analytic>
			<author>
				<persName>
					<surname>Cabrales</surname>
					<forename>Antonio</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Gossner</surname>
					<forename>Olivier</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Serrano</surname>
					<forename>Roberto</forename>
				</persName>
			</author>
			<title level="a">Entropy and the Value of Information for Investors</title>
		</analytic>
		<monogr>
			<title level="j">American Economic Review</title>
			<imprint>
				<date when="2013">2013</date>
				<biblScope unit="volume">103</biblScope>
				<biblScope unit="page" from="360" to="77"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b8">
		<monogr>
			<author>
				<persName>
					<surname>Caplin</surname>
					<forename>Andrew</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Dean</surname>
					<forename>Mark</forename>
				</persName>
			</author>
			<title level="m">The Behavioral Implications of Rational Inattention with Shannon Entropy</title>
			<imprint>
				<date when="2013">2013</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b9">
		<monogr>
			<author>
				<persName>
					<surname>Caplin</surname>
					<forename>Andrew</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Dean</surname>
					<forename>Mark</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Leahy</surname>
					<forename>John</forename>
				</persName>
			</author>
			<title level="m">Rationally Inattentive Behavior: Characterizing and Generalizing Shannon Entropy</title>
			<imprint>
				<date when="2017">2017</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b10">
		<analytic>
			<author>
				<persName>
					<surname>Caplin</surname>
					<forename>Andrew</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Dean</surname>
					<forename>Mark</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Leahy</surname>
					<forename>John</forename>
				</persName>
			</author>
			<title level="a">Psychological Expected Utility Theory and Anticipatory Feelings</title>
		</analytic>
		<monogr>
			<title level="j">Quarterly Journal of Economics</title>
			<imprint>
				<date when="2001">2001</date>
				<biblScope unit="volume">116</biblScope>
				<biblScope unit="page" from="55" to="79"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="book" xml:id="b11">
		<monogr>
			<author>
				<persName>
					<surname>Cover</surname>
					<forename type="first">Thomas</forename><forename type="middle">A</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Thomas</surname>
					<forename type="first">Joy</forename><forename type="middle">A</forename>
				</persName>
			</author>
			<title level="m">Elements of Information Theory</title>
			<imprint>
				<publisher>John Wiley &amp; Sons</publisher>
				<pubPlace>New York</pubPlace>
				<date when="2012">2012</date>
			</imprint>
		</monogr>
	</biblStruct>

	
	<biblStruct type="article" xml:id="b12">
		<analytic>
			<author>
				<persName>
					<surname>Csiszar</surname>
					<forename>Imre</forename>
				</persName>
			</author>
			<title level="a">Axiomatic Characterizations of Information Measures</title>
		</analytic>
		<monogr>
			<title level="j">Entropy</title>
			<imprint>
				<date when="2008">2008</date>
				<biblScope unit="volume">10</biblScope>
				<biblScope unit="page" from="261" to="73"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b13">
		<monogr>
			<author>
				<persName>
					<surname>De Lara</surname>
					<forename>Michel</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Gossner</surname>
					<forename>Olivier</forename>
				</persName>
			</author>
			<title level="m">An Instrumental Approach to the Value of Information</title>
			<imprint>
				<date when="2017">2017</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b14">
		<analytic>
			<author>
				<persName>
					<surname>Ely</surname>
					<forename>Jeff</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Frankel</surname>
					<forename>Alexander</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Kamenica</surname>
					<forename>Emir</forename>
				</persName>
			</author>
			<title level="a">Suspense and Surprise</title>
		</analytic>
		<monogr>
			<title level="j">Journal of Political Economy</title>
			<imprint>
				<date when="2015">2015</date>
				<biblScope unit="volume">123</biblScope>
				<biblScope unit="page" from="215" to="60"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b15">
		<analytic>
			<author>
				<persName>
					<surname>Gentzkow</surname>
					<forename>Matthew</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Kamenica</surname>
					<forename>Emir</forename>
				</persName>
			</author>
			<title level="a">Costly Persuasion</title>
		</analytic>
		<monogr>
			<title level="j">American Economic Review</title>
			<imprint>
				<date when="2014">2014</date>
				<biblScope unit="volume">104</biblScope>
				<biblScope unit="page" from="457" to="462"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b16">
		<analytic>
			<author>
				<persName>
					<surname>Gentzkow</surname>
					<forename>Matthew</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Kamenica</surname>
					<forename>Emir</forename>
				</persName>
			</author>
			<title level="a">Bayesian Persuasion with Multiple Senders and Rich Signal Spaces</title>
		</analytic>
		<monogr>
			<title level="j">Games and Economic Behavior</title>
			<imprint>
				<date when="2017">2017</date>
				<biblScope unit="volume">104</biblScope>
				<biblScope unit="page" from="411" to="429"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b17">
		<analytic>
			<author>
				<persName>
					<surname>Gneiting</surname>
					<forename>Tilmann</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Raftery</surname>
					<forename type="first">Adrian</forename><forename type="middle">E</forename>
				</persName>
			</author>
			<title level="a">Strictly Proper Scoring Rules, Prediction, and Estimation</title>
		</analytic>
		<monogr>
			<title level="j">Journal of the American Statistical Association</title>
			<imprint>
				<date when="2007">2007</date>
				<biblScope unit="volume">102</biblScope>
				<biblScope unit="page" from="359" to="378"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b18">
		<analytic>
			<author>
				<persName>
					<surname>Good</surname>
					<forename type="first">I</forename><forename type="middle">J</forename>
				</persName>
			</author>
			<title level="a">Rational Decisions</title>
		</analytic>
		<monogr>
			<title level="j">Journal of the Royal Statistical Society Series B (Methodological)</title>
			<imprint>
				<date when="1952">1952</date>
				<biblScope unit="volume">14</biblScope>
				<biblScope unit="page" from="107" to="114"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b19">
		<monogr>
			<author>
				<persName>
					<surname>Green</surname>
					<forename type="first">Jerry</forename><forename type="middle">R</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Stokey</surname>
					<forename type="first">Nancy</forename><forename type="middle">L</forename>
				</persName>
			</author>
			<title level="m">Two Representations of Information Structures and Their Comparisons</title>
			<imprint>
				<date when="1978">1978</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b20">
		<monogr>
			<author>
				<persName>
					<surname>Hebert</surname>
					<forename>Benjamin</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Woodford</surname>
					<forename>Michael</forename>
				</persName>
			</author>
			<title level="m">Rational Inattention with Sequential Information Sampling</title>
			<imprint>
				<date when="2017">2017</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b21">
		<analytic>
			<author>
				<persName>
					<surname>Kamenica</surname>
					<forename>Emir</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Gentzkow</surname>
					<forename>Matthew</forename>
				</persName>
			</author>
			<title level="a">Bayesian Persuasion</title>
		</analytic>
		<monogr>
			<title level="j">American Economic Review</title>
			<imprint>
				<date when="2011">2011</date>
				<biblScope unit="volume">101</biblScope>
				<biblScope unit="page" from="2590" to="2615"/>
			</imprint>
		</monogr>
	</biblStruct>	
	
	<biblStruct type="article" xml:id="b22">
		<analytic>
			<author>
				<persName>
					<surname>Lehmann</surname>
					<forename type="first">Erich</forename><forename type="middle">L</forename>
				</persName>
			</author>
			<title level="a">Comparing Location Experiments</title>
		</analytic>
		<monogr>
			<title level="j">Annals of Statistics</title>
			<imprint>
				<date when="1988">1988</date>
				<biblScope unit="volume">16</biblScope>
				<biblScope unit="page" from="521" to="533"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b23">
		<monogr>
			<author>
				<persName>
					<surname>Mensch</surname>
					<forename>Jeffrey</forename>
				</persName>
			</author>
			<title level="m">Cardinal Representations of Information</title>
			<imprint>
				<date when="2018">2018</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b24">
		<monogr>
			<author>
				<persName>
					<surname>Morris</surname>
					<forename>Stephen</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Strack</surname>
					<forename>Philip</forename>
				</persName>
			</author>
			<title level="m">The Wald Problem and the Equivalence of Sequential Sampling and Static Information Costs</title>
			<imprint>
				<date when="2017">2017</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b25">
		<analytic>
			<author>
				<persName>
					<surname>Persico</surname>
					<forename>Nicola</forename>
				</persName>
			</author>
			<title level="a">Information Acquisition in Auctions</title>
		</analytic>
		<monogr>
			<title level="j">Econometrica</title>
			<imprint>
				<date when="2000">2000</date>
				<biblScope unit="volume">68</biblScope>
				<biblScope unit="page" from="135" to="148"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b26">
		<analytic>
			<author>
				<persName>
					<surname>Schervish</surname>
					<forename type="first">Schervish</forename><forename type="middle">J</forename>
				</persName>
			</author>
			<title level="a">A General Method for Comparing Probability Assessors</title>
		</analytic>
		<monogr>
			<title level="j">Annals of Statistics</title>
			<imprint>
				<date when="1989">1989</date>
				<biblScope unit="volume">17</biblScope>
				<biblScope unit="page" from="1856" to="1879"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b27">
		<analytic>
			<author>
				<persName>
					<surname>Sims</surname>
					<forename type="first">Christopher</forename><forename type="middle">A</forename>
				</persName>
			</author>
			<title level="a">Implications of Rational Inattention</title>
		</analytic>
		<monogr>
			<title level="j">Journal of Monetary Economics</title>
			<imprint>
				<date when="2003">2003</date>
				<biblScope unit="volume">50</biblScope>
				<biblScope unit="page" from="665" to="690"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="article" xml:id="b28">
		<analytic>
			<author>
				<persName>
					<surname>Steiner</surname>
					<forename>Jakub</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Stewart</surname>
					<forename>Colin</forename>
				</persName>
			</author>
			<author>
				<persName>
					<surname>Matejka</surname>
					<forename>Filip</forename>
				</persName>
			</author>
			<title level="a">Rational Inattention Dynamics: Inertia and Delay in Decision-Making</title>
		</analytic>
		<monogr>
			<title level="j">Econometrica</title>
			<imprint>
				<date when="2017">2017</date>
				<biblScope unit="volume">85</biblScope>
				<biblScope unit="page" from="521" to="553"/>
			</imprint>
		</monogr>
	</biblStruct>
	
	<biblStruct type="unpublished" xml:id="b29">
		<monogr>
			<author>
				<persName>
					<surname>Yoder</surname>
					<forename>Nathan</forename>
				</persName>
			</author>
			<title level="m">Designing Incentives for Academic Research</title>
			<imprint>
				<date when="2016">2016</date>
			</imprint>
			<note>Unpublished</note>
		</monogr>
	</biblStruct>
		
	</listBibl>

		
	</div>
		</back>
	</text>
</TEI>
