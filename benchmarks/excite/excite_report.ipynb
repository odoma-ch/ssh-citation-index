{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citation_index.core.extractors import ExtractorFactory\n",
    "import pandas as pd\n",
    "import json\n",
    "from Levenshtein import ratio as levenshtein_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking results of EXCITE dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EXCITE dataset Overview\n",
    "\n",
    "* Papers are divided into two groups (according to their language) and there are six different folders in each groups.\n",
    "1. German_papers\n",
    "   - There are 225 papers in this folder.\n",
    "   - 219 paper with reference section at the end of document\n",
    "   - 12 paper with references in footnote and at the end of document\n",
    "   - 20 paper with references in footnote\n",
    "2. English_papers\n",
    "   - There are 100 papers in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 351\n",
      "Total pages: 8041\n",
      "Total references: 10171\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_df = pd.read_csv(\"pdf_files_info.csv\")\n",
    "references_data = json.load(open(\"all_references.json\", \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "print('EXgoldstandard dataset:')\n",
    "print(f\"Total documents: {len(pdf_df)}\")\n",
    "print(f\"Total pages: {pdf_df['page_count'].sum()}\")\n",
    "print(f\"Total references: {sum(len(data['references']) for data in references_data.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE PDF DATA ===\n",
      " file_id  filename  class lang                                                                                                                       file_path  page_count\n",
      "   28725 28725.pdf      1   en EXgoldstandard/Goldstandard_EXparser/2-English_papers/1-English_papers(with_reference_section_at_end_of_paper)/1-pdfs/28725.pdf          15\n",
      "    6026  6026.pdf      1   de    EXgoldstandard/Goldstandard_EXparser/1-German_papers/1-German_papers(with_reference_section_at_end_of_paper)/1-pdfs/6026.pdf          11\n",
      "    1630  1630.pdf      1   en  EXgoldstandard/Goldstandard_EXparser/2-English_papers/1-English_papers(with_reference_section_at_end_of_paper)/1-pdfs/1630.pdf          13\n",
      "   19174 19174.pdf      1   de   EXgoldstandard/Goldstandard_EXparser/1-German_papers/1-German_papers(with_reference_section_at_end_of_paper)/1-pdfs/19174.pdf          10\n",
      "   55362 55362.pdf      1   en EXgoldstandard/Goldstandard_EXparser/2-English_papers/1-English_papers(with_reference_section_at_end_of_paper)/1-pdfs/55362.pdf          10\n",
      "\n",
      "=== SAMPLE REFERENCES DATA ===\n",
      "Paper 1 (ID: 26236):\n",
      "  Number of references: 14\n",
      "  First few references:\n",
      "    1. Statistisches Bundesamt (1978a): Volkszählung vom 27. Mai 1970. Methodische und praktische Vorbereitung sowie Durchführung der Volkszählung 1970. Fachserie 1 Heft 25. Stuttgart/Mainz: Kohlhammer.\n",
      "    2. Statistisches Bundesamt (1978b): Volkszählung vom 27. Mai 1970. Untersuchungen zur Methode und Genauigkeit der Volkszählung 1970. Fachserie 1 Heft 26. Stuttgart/Mainz: Kohlhammer.\n",
      "    3. \"Statistisches Bundesamt (1972): Ausgewählte Strukturdaten für Bund und Länder. Fachserie A: Bevölkerung und Kultur. Volkszählung vom 27. Mai 1970, Heft 1.\"\n",
      "    ... and 11 more\n",
      "\n",
      "Paper 2 (ID: 45544):\n",
      "  Number of references: 40\n",
      "  First few references:\n",
      "    1. Arends-Tòth, J. / Van de Vijver, F. J. (2003): Multiculturalism and acculturation: Views of Dutch and Turkish-Dutch. European Journal of Social Psychology 33(2), S. 249-266.\n",
      "    2. Arends-Tóth, J. / Van de Vijver, F. J. (2006a): Assessment of psychological acculturation. In: Sam, D. L. / Berry, J. W. (Hrsg.): The camebridge handbook of acculturation psychology. New York: Cambridge University Press, S. 142-162.\n",
      "    3. Arends-Tóth, J. / Van de Vijver, F. J. (2006b): Issues in the conceptualization and assessment of acculturation. In: Bornstein, M. H. / Cote, L. R. (Hrsg.): Acculturation and parent child relationships: Measurement and development. Mahwah, NJ: Erlbaum, S. 33-62.\n",
      "    ... and 37 more\n",
      "\n",
      "Paper 3 (ID: 11129):\n",
      "  Number of references: 33\n",
      "  First few references:\n",
      "    1. \"Arnold, Michael; Strehl, Rüdiger, 2000: Wie kommen Innovationen ins DRG-System? (Die Steuerungsfunktion der Bundesauschüsse), in: Michael Arnold; Martin Litsch; Henner Schellenschmidt (Hg.): Krankenhaus-Report 2000. Schwerpunkt: Vergütungsreform mit DRGs. Stuttgart: Schattauer, 159-171.\"\n",
      "    2. \"Beske, Fritz, 2001: Neubestimmung und Finanzierung des Leistungskatalogs der gesetzlichen Krankenversicherung: Kieler Konzept – Paradigmenwechsel im Gesundheitswesen. Berlin u.a.: Quintessenz.\"\n",
      "    3. \"Borchert, Günter, 1999: „Sicherung der Verbindlichkeit untergesetzlicher Normen im Krankenversicherungsrecht“, Die Krankenversicherung 51: 273-275.\"\n",
      "    ... and 30 more\n",
      "\n",
      "Paper 4 (ID: 38381):\n",
      "  Number of references: 23\n",
      "  First few references:\n",
      "    1. Baron, Ch. und Ch. Lassalle. 1915. Dictionnaire des communes administratif & militaire. 12. Aufl. Paris: Charles-Lavauzelle.\n",
      "    2. Blumenauer, Elke. 2000. Journalismus zwischen Pressefreiheit und Zensur. Die Augsburger „Allgemeine Zeitung“ im Karlsbader System (1818-1848) (Medien in Geschichte und Gegenwart, Bd. 14). Köln: Böhlau.\n",
      "    3. Bohrmann, Hans und Gabriele Toepser-Ziegert, eds. 2003. Mikrofilmarchiv der deutschsprachigen Presse e.V.11. Bestandsverzeichnis. Berlin: Vistas.\n",
      "    ... and 20 more\n",
      "\n",
      "Paper 5 (ID: 24743):\n",
      "  Number of references: 58\n",
      "  First few references:\n",
      "    1. Arnold, T./Stuewe, G., 1993: Jugend - Gewalt - Gangs der zweiten Migrantengeneration. Sozialmagazin 18: 40-47.\n",
      "    2. Aster, R./Kuckartz, U., 1988: Jugend und Schule. Eine Sekundäranalyse schulspezifischer Fragen der Shell-Studie „Jugendliche und Erwachsene `85“. Zeitschrift für Sozialisationsforschung und Erziehungssoziologie 8: 200-212.\n",
      "    3. Baacke, D., 1993: Jugend und Jugendkulturen. Darstellung und Deutung. Weinheim, München: Juventa.\n",
      "    ... and 55 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sample_data(pdf_df, references_data, n_samples=5):\n",
    "    \"\"\"Display sample data for verification\"\"\"\n",
    "    print(f\"\\n=== SAMPLE PDF DATA ===\")\n",
    "    if not pdf_df.empty:\n",
    "        print(pdf_df.sample(n_samples).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n=== SAMPLE REFERENCES DATA ===\")\n",
    "    if references_data:\n",
    "        sample_keys = list(references_data.keys())[:n_samples]\n",
    "        for i, file_id in enumerate(sample_keys):\n",
    "            ref_data = references_data[file_id]\n",
    "            print(f\"Paper {i+1} (ID: {file_id}):\")\n",
    "            print(f\"  Number of references: {len(ref_data['references'])}\")\n",
    "            print(f\"  First few references:\")\n",
    "            for j, ref in enumerate(ref_data['references'][:3]):\n",
    "                print(f\"    {j+1}. {ref}\")\n",
    "            if len(ref_data['references']) > 3:\n",
    "                print(f\"    ... and {len(ref_data['references']) - 3} more\")\n",
    "            print()\n",
    "            \n",
    "get_sample_data(pdf_df, references_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add reference_count to pdf_df\n",
    "pdf_df['reference_count'] = pdf_df['file_id'].map(lambda x: len(references_data[str(x)]['references']))\n",
    "pdf_df['reference_count'].plot(kind='hist', bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_df['page_count'].plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Benchmarking Results\n",
    "\n",
    "\n",
    "### 2.1 Reference Extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alex/docs/code/Odoma/citation_index\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/alex/docs/code/Odoma/citation_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: benchmarks/excite/outputs\n",
      "Loaded 351 PDF records and 351 papers with references.\n",
      "Loaded 0 LLM responses from benchmarks/excite/outputs/extraction_google_gemma_3_27b_it_pymupdf_20250718_094828_responses.pkl. Skipping LLM calls.\n",
      "Evaluating 0 responses.\n",
      "Evaluating responses: 0it [00:00, ?it/s]\n",
      "Skipping saving results & metrics (--skip_save enabled).\n",
      "WARNING:root:No metrics were generated.\n",
      "LLM calls were skipped (responses loaded from file).\n"
     ]
    }
   ],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task extraction \\\n",
    "  --model_name mistralai/Mistral-Small-3.1-24B-Instruct-2503 \\\n",
    "  --api_key dummy_key \\\n",
    "  --responses_path benchmarks/excite/outputs/extraction_google_gemma_3_27b_it_pymupdf_20250718_094828_responses.pkl \\\n",
    "  --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Reference Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task parsing \\\n",
    "  --model_name deepseek-ai/DeepSeek-Chat \\\n",
    "  --api_key dummy_key \\\n",
    "  --responses_path benchmarks/excite/outputs/parsing_deepseek_chat_pymupdf_20250718_001828_responses.pkl \\\n",
    "  --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Summary\n",
    "\n",
    "```\n",
    "{\n",
    "  \"precision\": 0.8270206896551726,\n",
    "  \"recall\": 0.7789028735632184,\n",
    "  \"micro_f1\": 0.7816902298850574,\n",
    "  \"macro_f1\": 0.7593508620689655\n",
    "}\n",
    "```\n",
    "\n",
    "#### Focused field F1 scores\n",
    "\n",
    "```\n",
    "  authors: 0.7700\n",
    "  full_title: 0.7552\n",
    "  publication_date: 0.8468\n",
    "```\n",
    "\n",
    "####  Error statistics\n",
    "\n",
    "```\n",
    "  Parsing errors:   6\n",
    "  Evaluation errors: 1\n",
    "```\n",
    "\n",
    "#### Per-class / language metrics\n",
    "\n",
    "```\n",
    "  class 1, lang de: precision: 0.8450, recall: 0.8296, micro_f1: 0.8262, macro_f1: 0.8121\n",
    "  class 1, lang en: precision: 0.8088, recall: 0.7264, micro_f1: 0.7310, macro_f1: 0.7138\n",
    "  class 2, lang de: precision: 0.7401, recall: 0.6578, micro_f1: 0.6878, macro_f1: 0.5929\n",
    "  class 3, lang de: precision: 0.8083, recall: 0.4499, micro_f1: 0.5286, macro_f1: 0.4072\n",
    "LLM calls were skipped (responses loaded from file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task parsing \\\n",
    "  --model_name google/gemma-3-27b-it \\\n",
    "  --api_key dummy_key \\\n",
    "  --responses_path benchmarks/excite/outputs/parsing_google_gemma_3_27b_it_pymupdf_20250718_013725_responses.pkl \\\n",
    "  --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Summary\n",
    "```\n",
    "{\n",
    "  \"precision\": 0.8102494219653177,\n",
    "  \"recall\": 0.8093760115606935,\n",
    "  \"micro_f1\": 0.8053809248554913,\n",
    "  \"macro_f1\": 0.7879118497109827\n",
    "}\n",
    "```\n",
    "\n",
    "#### Focused field F1 scores\n",
    "```\n",
    "  authors: 0.7793\n",
    "  full_title: 0.7693\n",
    "  publication_date: 0.8993  \n",
    "```\n",
    "\n",
    "#### Error statistics\n",
    "```\n",
    "  Parsing errors:   0\n",
    "  Evaluation errors: 1\n",
    "```\n",
    "\n",
    "#### Per-class / language metrics\n",
    "```\n",
    "  class 1, lang de: precision: 0.8353, recall: 0.8525, micro_f1: 0.8422, macro_f1: 0.8320\n",
    "  class 1, lang en: precision: 0.7803, recall: 0.7815, micro_f1: 0.7775, macro_f1: 0.7652\n",
    "  class 2, lang de: precision: 0.7312, recall: 0.6604, micro_f1: 0.6835, macro_f1: 0.6077\n",
    "  class 3, lang de: precision: 0.7069, recall: 0.4636, micro_f1: 0.5356, macro_f1: 0.4421\n",
    "LLM calls were skipped (responses loaded from file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task parsing \\\n",
    "  --model_name mistralai/Mistral-Small-3.1-24B-Instruct-2503 \\\n",
    "  --api_key dummy_key \\\n",
    "  --responses_path /Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/outputs/parsing_mistralai_Mistral_Small_3.1_24B_Instruct_2503_pymupdf_20250718_094356_responses.pkl \\\n",
    "  --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmark Summary\n",
    "```\n",
    "{\n",
    "  \"precision\": 0.7922778097982708,\n",
    "  \"recall\": 0.7984573487031701,\n",
    "  \"micro_f1\": 0.7927835734870317,\n",
    "  \"macro_f1\": 0.7770432276657061\n",
    "}\n",
    "```\n",
    "\n",
    "#### Focused field F1 scores\n",
    "```\n",
    "  authors: 0.7647\n",
    "  full_title: 0.7699\n",
    "  publication_date: 0.8689\n",
    "```\n",
    "\n",
    "#### Error statistics\n",
    "```\n",
    "  Parsing errors:   18\n",
    "  Evaluation errors: 2\n",
    "```\n",
    "\n",
    "#### Per-class / language metrics\n",
    "```\n",
    "  class 1, lang de: precision: 0.8240, recall: 0.8392, micro_f1: 0.8299, macro_f1: 0.8190\n",
    "  class 1, lang en: precision: 0.7557, recall: 0.7737, micro_f1: 0.7638, macro_f1: 0.7618\n",
    "  class 2, lang de: precision: 0.6192, recall: 0.5870, micro_f1: 0.5999, macro_f1: 0.5213\n",
    "  class 3, lang de: precision: 0.8157, recall: 0.5916, micro_f1: 0.6686, macro_f1: 0.5412\n",
    "LLM calls were skipped (responses loaded from file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reference Extraction and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py --task extraction_and_parsing \\\n",
    "  --method 1 \\\n",
    "  --model_name deepseek-chat \\\n",
    "  --api_base https://api.deepseek.com/v1 \\\n",
    "  --prompt_name reference_extraction_and_parsing.md \\\n",
    "  --save_scores extraction_and_parsing_results_summary.txt \\\n",
    "  --per_class \\\n",
    "  --focus_fields authors,full_title,publication_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXCITE Benchmark Summary\n",
    "\n",
    "``` \n",
    "{\n",
    "  \"precision\": 0.8895544642857144,\n",
    "  \"recall\": 0.8184675595238096,\n",
    "  \"micro_f1\": 0.821274107142857,\n",
    "  \"macro_f1\": 0.7833875000000001\n",
    "}\n",
    "```\n",
    "\n",
    "Focused field F1 scores:\n",
    "```\n",
    "  authors: 0.8195\n",
    "  full_title: 0.8177\n",
    "  publication_date: 0.8289\n",
    "```\n",
    "\n",
    "Error statistics:\n",
    "```\n",
    "  Parsing errors:   7\n",
    "  Evaluation errors: 0\n",
    "```\n",
    "\n",
    "Per-class / language metrics:\n",
    "```\n",
    "  class 1, lang de: precision: 0.8760, recall: 0.8332, micro_f1: 0.8271, macro_f1: 0.7950\n",
    "  class 1, lang en: precision: 0.9269, recall: 0.8789, micro_f1: 0.8768, macro_f1: 0.8567\n",
    "  class 2, lang de: precision: 0.8264, recall: 0.5865, micro_f1: 0.6595, macro_f1: 0.5142\n",
    "  class 3, lang de: precision: 0.8698, recall: 0.3565, micro_f1: 0.4493, macro_f1: 0.3306\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task extraction_and_parsing \\\n",
    "  --api_key dummy_key \\\n",
    "  --responses_path benchmarks/excite/outputs/extraction_and_parsing_google_gemma_3_27b_it_pymupdf_20250718_004905_responses.pkl \\\n",
    "  --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXCITE Benchmark Summary\n",
    "\n",
    "```\n",
    "{\n",
    "  \"precision\": 0.8556907514450866,\n",
    "  \"recall\": 0.7192731213872832,\n",
    "  \"micro_f1\": 0.7454543352601157,\n",
    "  \"macro_f1\": 0.675514739884393\n",
    "}\n",
    "```\n",
    "\n",
    "Focused field F1 scores:\n",
    "```\n",
    "  authors: 0.7498\n",
    "  full_title: 0.7373\n",
    "  publication_date: 0.7473\n",
    "```\n",
    "\n",
    "Error statistics:\n",
    "```\n",
    "  Parsing errors:   9\n",
    "  Evaluation errors: 0\n",
    "```\n",
    "\n",
    "Per-class / language metrics:\n",
    "```\n",
    "  class 1, lang de: precision: 0.8500, recall: 0.7513, micro_f1: 0.7641, macro_f1: 0.7031\n",
    "  class 1, lang en: precision: 0.9071, recall: 0.7621, micro_f1: 0.7990, macro_f1: 0.7359\n",
    "  class 2, lang de: precision: 0.6226, recall: 0.3455, micro_f1: 0.4048, macro_f1: 0.2645\n",
    "  class 3, lang de: precision: 0.8816, recall: 0.3475, micro_f1: 0.4728, macro_f1: 0.3064\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: benchmarks/excite/outputs\n",
      "Loaded 351 PDF records and 351 papers with references.\n",
      "Loaded layout model s3://layout/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_28 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device mps with dtype torch.float16\n",
      "Preparing tasks: 100%|█████████████████████| 351/351 [00:00<00:00, 16235.84it/s]\n",
      "Submitting 351 tasks to LLM with 25 workers (method 1).\n",
      "WARNING:langfuse:Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 131072 tokens. However, you requested 160268 tokens in the messages, Please reduce the length of the messages. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
      "ERROR:root:Task for 32707 generated an exception: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 131072 tokens. However, you requested 160268 tokens in the messages, Please reduce the length of the messages. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1034, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'object': 'error', 'message': \"This model's maximum context length is 131072 tokens. However, you requested 160268 tokens in the messages, Please reduce the length of the messages. None\", 'type': 'BadRequestError', 'param': None, 'code': 400}\n",
      "WARNING:langfuse:Request timed out.                                             \n",
      "ERROR:root:Task for 38465 generated an exception: Request timed out.            \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 987, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n",
      "WARNING:langfuse:Request timed out.                                             \n",
      "ERROR:root:Task for 32211 generated an exception: Request timed out.            \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 987, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n",
      "WARNING:langfuse:Request timed out.                                             \n",
      "ERROR:root:Task for 4930 generated an exception: Request timed out.             \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 987, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n",
      "WARNING:langfuse:Request timed out.                                             \n",
      "ERROR:root:Task for 30957 generated an exception: Request timed out.            \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 987, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n",
      "WARNING:langfuse:Request timed out.                                             \n",
      "ERROR:root:Task for 49817 generated an exception: Request timed out.            \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/connection.py\", line 103, in handle_request\n",
      "    return self._connection.handle_request(request)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 136, in handle_request\n",
      "    raise exc\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 106, in handle_request\n",
      "    ) = self._receive_response_headers(**kwargs)\n",
      "        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 177, in _receive_response_headers\n",
      "    event = self._receive_event(timeout=timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_sync/http11.py\", line 217, in _receive_event\n",
      "    data = self._network_stream.read(\n",
      "        self.READ_NUM_BYTES, timeout=timeout\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_backends/sync.py\", line 126, in read\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 969, in request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ReadTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 142, in run\n",
      "    response_str = future.result()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/benchmarks/excite/run_excite_bench.py\", line 202, in _execute_llm_call\n",
      "    refs = run_pdf_one_step(\n",
      "        text_or_pdf=input_text,\n",
      "    ...<3 lines>...\n",
      "        include_schema=include_schema,\n",
      "    )\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/pipelines/reference_extraction_and_parsing.py\", line 57, in run_pdf_one_step\n",
      "    response = llm_client.call(prompt.prompt, json_output=True, temperature=temperature, json_schema=prompt.json_schema)\n",
      "  File \"/Users/alex/docs/code/Odoma/citation_index/src/citation_index/llm/client.py\", line 58, in call\n",
      "    response = self.client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        max_tokens=max_tokens,\n",
      "        response_format=response_format)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 214, in wrapper\n",
      "    return func(open_ai_definitions, wrapped, args, kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 752, in _wrap\n",
      "    raise ex\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/langfuse/openai.py\", line 718, in _wrap\n",
      "    openai_response = wrapped(**arg_extractor.get_openai_args())\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<43 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 1239, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/default/lib/python3.13/site-packages/openai/_base_client.py\", line 987, in request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n",
      "Executing LLM calls: 100%|██████████████████| 351/351 [1:11:06<00:00, 12.16s/it]\n",
      "Saved LLM responses to benchmarks/excite/outputs/extraction_and_parsing_m1_mistralai_Mistral_Small_3.1_24B_Instruct_2503_marker_20250811_143853_responses.pkl\n",
      "Evaluating 345 responses.\n",
      "WARNING:root:Warning: No XML ground truth for 18268, skipping structured evaluation.\n",
      "WARNING:root:Warning: No XML ground truth for 6026, skipping structured evaluation.\n",
      "Evaluating responses: 100%|██████████████████| 345/345 [00:03<00:00, 111.16it/s]\n",
      "Saved raw results to benchmarks/excite/outputs/extraction_and_parsing_m1_mistralai_Mistral_Small_3.1_24B_Instruct_2503_marker_20250811_143856_results.pkl\n",
      "Saved metrics to benchmarks/excite/outputs/extraction_and_parsing_m1_mistralai_Mistral_Small_3.1_24B_Instruct_2503_marker_20250811_143856_metrics.csv\n",
      "\n",
      "--- EXCITE Benchmark Summary ---\n",
      "{\n",
      "  \"precision\": 0.6902276967930029,\n",
      "  \"recall\": 0.719034693877551,\n",
      "  \"micro_f1\": 0.6932760932944606,\n",
      "  \"macro_f1\": 0.6697609329446064\n",
      "}\n",
      "-------------------------\n",
      "\n",
      "Focused field F1 scores:\n",
      "  authors: 0.6786\n",
      "  full_title: 0.6990\n",
      "  publication_date: 0.7061\n",
      "-------------------------\n",
      "\n",
      "Error statistics:\n",
      "  Parsing errors:   0\n",
      "  Evaluation errors: 0\n",
      "Per-class / language metrics:\n",
      "  class 1, lang de: precision: 0.6569, recall: 0.6967, micro_f1: 0.6634, macro_f1: 0.6417\n",
      "  class 1, lang en: precision: 0.8380, recall: 0.8719, micro_f1: 0.8483, macro_f1: 0.8297\n",
      "  class 2, lang de: precision: 0.5060, recall: 0.4464, micro_f1: 0.4678, macro_f1: 0.4062\n",
      "  class 3, lang de: precision: 0.3227, recall: 0.1595, micro_f1: 0.1993, macro_f1: 0.1461\n",
      "Benchmark scores summary appended to: extraction_and_parsing_results_summary.txt\n",
      "LLM call execution time: 4266.48 seconds\n"
     ]
    }
   ],
   "source": [
    "!python benchmarks/excite/run_excite_bench.py \\\n",
    "  --task extraction_and_parsing \\\n",
    "  --model_name mistralai/Mistral-Small-3.1-24B-Instruct-2503 \\\n",
    "  --prompt_name reference_extraction_and_parsing.md \\\n",
    "  --save_scores extraction_and_parsing_results_summary.txt \\\n",
    "  --per_class \\\n",
    "  --focus_fields authors,full_title,publication_date\n",
    "  # --responses_path benchmarks/excite/outputs/extraction_and_parsing_mistralai_Mistral_Small_3.1_24B_Instruct_2503_pymupdf_20250718_034619_responses.pkl \\\n",
    "  # --per_class   --skip_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Summary\n",
    "```\n",
    "{\n",
    "  \"precision\": 0.6134388379204893,\n",
    "  \"recall\": 0.6388975535168194,\n",
    "  \"micro_f1\": 0.6139899082568807,\n",
    "  \"macro_f1\": 0.5859694189602446\n",
    "}\n",
    "```\n",
    "\n",
    "Focused field F1 scores:\n",
    "```\n",
    "authors: 0.5993\n",
    "  full_title: 0.6170\n",
    "  publication_date: 0.6307\n",
    "```\n",
    "\n",
    "Error statistics:\n",
    "```\n",
    "  Parsing errors:   35\n",
    "  Evaluation errors: 0\n",
    "```\n",
    "\n",
    "Per-class / language metrics:\n",
    "```\n",
    "  class 1, lang de: precision: 0.5951, recall: 0.6326, micro_f1: 0.5994, macro_f1: 0.5710\n",
    "  class 1, lang en: precision: 0.6817, recall: 0.7187, micro_f1: 0.6952, macro_f1: 0.6819\n",
    "  class 2, lang de: precision: 0.5098, recall: 0.4562, micro_f1: 0.4679, macro_f1: 0.4003\n",
    "  class 3, lang de: precision: 0.5272, recall: 0.3039, micro_f1: 0.3689, macro_f1: 0.2770\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
